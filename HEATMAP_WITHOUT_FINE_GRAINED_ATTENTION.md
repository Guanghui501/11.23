# èƒ½å¦åœ¨æ²¡æœ‰ç»†ç²’åº¦æ³¨æ„åŠ›çš„æƒ…å†µä¸‹æŸ¥çœ‹çƒ­å›¾ï¼Ÿ

## ğŸ¯ ç›´æ¥å›ç­”

**âŒ ä¸èƒ½**

å¦‚æœæ¨¡å‹é…ç½®ä¸­ `use_fine_grained_attention=False`ï¼Œåˆ™**æ— æ³•ç”Ÿæˆç»†ç²’åº¦æ³¨æ„åŠ›çƒ­å›¾**ï¼Œå› ä¸ºæ¨¡å‹ä¸ä¼šè®¡ç®—åŸå­-è¯çº§åˆ«çš„æ³¨æ„åŠ›æƒé‡ã€‚

---

## ğŸ“Š åŸå› è§£é‡Š

### çƒ­å›¾æ•°æ®æ¥æº

æ‚¨çœ‹åˆ°çš„æ³¨æ„åŠ›çƒ­å›¾ï¼ˆAtom â†’ Text, Text â†’ Atomï¼‰æ¥è‡ªäºï¼š

```python
# æ¨¡å‹è¾“å‡ºä¸­çš„è¿™ä¸ªå­—æ®µ:
output['fine_grained_attention_weights']

# å½¢çŠ¶: [num_heads, num_atoms, seq_len]
# è¡¨ç¤º: æ¯ä¸ªæ³¨æ„åŠ›å¤´ä¸­ï¼Œæ¯ä¸ªåŸå­å¯¹æ¯ä¸ªè¯çš„æ³¨æ„åŠ›æƒé‡
```

### æ¨¡å‹é…ç½®

åœ¨ `models/alignn.py` ä¸­æœ‰ä¸¤ä¸ªç‹¬ç«‹çš„å¼€å…³ï¼š

```python
class ALIGNNConfig(BaseSettings):
    # ä¸­æœŸèåˆ (Middle Fusion)
    use_middle_fusion: bool = False

    # ç»†ç²’åº¦æ³¨æ„åŠ› (Fine-Grained Attention)
    use_fine_grained_attention: bool = False  # â† è¿™ä¸ªæ§åˆ¶çƒ­å›¾æ•°æ®ï¼
```

**å…³é”®ç‚¹**ï¼š
- `use_middle_fusion` æ§åˆ¶æ˜¯å¦åœ¨ GNN ä¸­æ³¨å…¥æ–‡æœ¬ä¿¡æ¯
- `use_fine_grained_attention` æ§åˆ¶æ˜¯å¦è®¡ç®—åŸå­-è¯çº§åˆ«çš„æ³¨æ„åŠ›
- **åªæœ‰ `use_fine_grained_attention=True` æ‰ä¼šç”Ÿæˆçƒ­å›¾æ•°æ®ï¼**

---

## ğŸ” å››ç§é…ç½®ç»„åˆ

### é…ç½® 1: æ— ä¸­æœŸèåˆ + æ— ç»†ç²’åº¦æ³¨æ„åŠ›
```python
use_middle_fusion = False
use_fine_grained_attention = False
```
- âŒ **æ— æ³•ç”Ÿæˆçƒ­å›¾**
- æ¨¡å‹åªè¾“å‡ºé¢„æµ‹ç»“æœï¼Œæ²¡æœ‰æ³¨æ„åŠ›æƒé‡

### é…ç½® 2: æ— ä¸­æœŸèåˆ + æœ‰ç»†ç²’åº¦æ³¨æ„åŠ›
```python
use_middle_fusion = False
use_fine_grained_attention = True
```
- âœ… **å¯ä»¥ç”Ÿæˆçƒ­å›¾**
- è¿™å°±æ˜¯æ‚¨ä¹‹å‰å±•ç¤ºçš„"æ— ä¸­æœŸèåˆ"çƒ­å›¾
- èŠ‚ç‚¹ç‰¹å¾ä¸åŒ…å«æ–‡æœ¬è¯­ä¹‰ â†’ æ³¨æ„åŠ›åˆ†æ•£åˆ°æ— ç”¨è¯

### é…ç½® 3: æœ‰ä¸­æœŸèåˆ + æ— ç»†ç²’åº¦æ³¨æ„åŠ›
```python
use_middle_fusion = True
use_fine_grained_attention = False
```
- âŒ **æ— æ³•ç”Ÿæˆçƒ­å›¾**
- è™½ç„¶èŠ‚ç‚¹ç‰¹å¾åŒ…å«æ–‡æœ¬è¯­ä¹‰ï¼Œä½†æ²¡æœ‰è®¡ç®—æ³¨æ„åŠ›æƒé‡

### é…ç½® 4: æœ‰ä¸­æœŸèåˆ + æœ‰ç»†ç²’åº¦æ³¨æ„åŠ›ï¼ˆæ¨èï¼‰
```python
use_middle_fusion = True
use_fine_grained_attention = True
```
- âœ… **å¯ä»¥ç”Ÿæˆçƒ­å›¾**
- è¿™æ˜¯æ‚¨å½“å‰çš„å…¨æ¨¡æ€æ¨¡å‹é…ç½®
- èŠ‚ç‚¹ç‰¹å¾åŒ…å«æ–‡æœ¬è¯­ä¹‰ â†’ æ³¨æ„åŠ›é›†ä¸­ï¼Œè¿‡æ»¤æ— ç”¨è¯

---

## ğŸ’¡ ä¸ºä»€ä¹ˆéœ€è¦ Fine-Grained Attentionï¼Ÿ

### æ¨¡å‹å‰å‘ä¼ æ’­æµç¨‹

```
è¾“å…¥: ç»“æ„ (g) + æ–‡æœ¬ (text)
    â†“
GNN ç¼–ç  (å¯é€‰: Middle Fusion åœ¨è¿™é‡Œæ³¨å…¥æ–‡æœ¬)
    â†“
èŠ‚ç‚¹ç‰¹å¾: [num_atoms, hidden_dim]
æ–‡æœ¬ç‰¹å¾: [seq_len, hidden_dim]
    â†“
å¦‚æœ use_fine_grained_attention == True:
    â†“
    Fine-Grained Attention Module
    â†“
    è®¡ç®—: Attention(nodes, text_tokens)
    â†“
    è¾“å‡º: attention_weights [num_heads, num_atoms, seq_len]
    â†“
    è¿™å°±æ˜¯çƒ­å›¾çš„æ•°æ®ï¼

å¦‚æœ use_fine_grained_attention == False:
    â†“
    è·³è¿‡æ³¨æ„åŠ›è®¡ç®—
    â†“
    æ²¡æœ‰ attention_weights
    â†“
    æ— æ³•ç”Ÿæˆçƒ­å›¾
```

### Fine-Grained Attention æ¨¡å—çš„ä½œç”¨

```python
class FineGrainedCrossModalAttention(nn.Module):
    """
    è®¡ç®—åŸå­å’Œæ–‡æœ¬tokenä¹‹é—´çš„å¤šå¤´æ³¨æ„åŠ›

    è¾“å…¥:
        node_features: [batch_size, num_atoms, hidden_dim]
        token_features: [batch_size, seq_len, hidden_dim]

    è¾“å‡º:
        enhanced_nodes: å¢å¼ºçš„èŠ‚ç‚¹ç‰¹å¾
        enhanced_tokens: å¢å¼ºçš„tokenç‰¹å¾
        attention_weights: [batch_size, num_heads, num_atoms, seq_len] â† çƒ­å›¾æ•°æ®ï¼
    """
```

**æ²¡æœ‰è¿™ä¸ªæ¨¡å—ï¼Œå°±æ²¡æœ‰ attention_weightsï¼Œä¹Ÿå°±æ— æ³•ç»˜åˆ¶çƒ­å›¾ï¼**

---

## ğŸ”¬ å¦‚ä½•æ£€æŸ¥æ‚¨çš„æ¨¡å‹é…ç½®

### æ–¹æ³• 1: æ£€æŸ¥æ¨¡å‹è¾“å‡º

```python
# åŠ è½½æ¨¡å‹
model = load_model(checkpoint_path)

# å‰å‘ä¼ æ’­
output = model(g, lg, text)

# æ£€æŸ¥æ˜¯å¦æœ‰ç»†ç²’åº¦æ³¨æ„åŠ›æƒé‡
if 'fine_grained_attention_weights' in output:
    print("âœ… æ¨¡å‹å¯ç”¨äº†ç»†ç²’åº¦æ³¨æ„åŠ›ï¼Œå¯ä»¥ç”Ÿæˆçƒ­å›¾")
    fg_attn = output['fine_grained_attention_weights']
    print(f"   å½¢çŠ¶: {fg_attn.shape}")
else:
    print("âŒ æ¨¡å‹æœªå¯ç”¨ç»†ç²’åº¦æ³¨æ„åŠ›ï¼Œæ— æ³•ç”Ÿæˆçƒ­å›¾")
```

### æ–¹æ³• 2: æ£€æŸ¥æ¨¡å‹é…ç½®

```python
# æ£€æŸ¥æ¨¡å‹é…ç½®
config = model.config

print(f"use_middle_fusion: {config.use_middle_fusion}")
print(f"use_fine_grained_attention: {config.use_fine_grained_attention}")

if config.use_fine_grained_attention:
    print("âœ… å¯ä»¥ç”Ÿæˆçƒ­å›¾")
else:
    print("âŒ æ— æ³•ç”Ÿæˆçƒ­å›¾")
```

### æ–¹æ³• 3: ä½¿ç”¨è¯Šæ–­è„šæœ¬

```bash
# è¿è¡Œè¯Šæ–­
python diagnose_model_attention.py \
    --model_path /path/to/checkpoint.pt \
    --cif_path /path/to/structure.cif \
    --text "description"

# å¦‚æœè¾“å‡º:
#   "é”™è¯¯: æ¨¡å‹è¾“å‡ºä¸­æ²¡æœ‰ fine_grained_attention_weights"
# è¯´æ˜æ¨¡å‹æœªå¯ç”¨ç»†ç²’åº¦æ³¨æ„åŠ›
```

---

## ğŸ“‹ ä¸åŒåœºæ™¯çš„è§£å†³æ–¹æ¡ˆ

### åœºæ™¯ 1: æ‚¨åªæœ‰ä¸€ä¸ªè®­ç»ƒå¥½çš„æ¨¡å‹

**é—®é¢˜**: æ¨¡å‹è®­ç»ƒæ—¶ `use_fine_grained_attention=False`

**è§£å†³æ–¹æ¡ˆ**: âŒ æ— æ³•ç”Ÿæˆçƒ­å›¾

**åŸå› **:
- æ¨¡å‹æƒé‡ä¸­ä¸åŒ…å« `FineGrainedCrossModalAttention` æ¨¡å—
- æ— æ³•åæœŸæ·»åŠ ï¼Œå› ä¸ºè¯¥æ¨¡å—éœ€è¦è®­ç»ƒ

**å»ºè®®**: é‡æ–°è®­ç»ƒæ¨¡å‹ï¼Œè®¾ç½® `use_fine_grained_attention=True`

### åœºæ™¯ 2: æ‚¨æƒ³å¯¹æ¯”ä¸åŒé…ç½®

**ç›®æ ‡**: å¯¹æ¯”ä»¥ä¸‹é…ç½®çš„çƒ­å›¾å·®å¼‚
- æ— ä¸­æœŸèåˆ + æœ‰ç»†ç²’åº¦æ³¨æ„åŠ›
- æœ‰ä¸­æœŸèåˆ + æœ‰ç»†ç²’åº¦æ³¨æ„åŠ›

**è§£å†³æ–¹æ¡ˆ**: âœ… å¯ä»¥

**è¦æ±‚**: ä¸¤ä¸ªæ¨¡å‹éƒ½éœ€è¦ `use_fine_grained_attention=True`

**ç¤ºä¾‹**:
```bash
# æ¨¡å‹ A: æ— ä¸­æœŸèåˆ
python demo_robust_attention.py \
    --model_path model_no_middle_fusion.pt \
    --save_dir ./no_middle

# æ¨¡å‹ B: æœ‰ä¸­æœŸèåˆ
python demo_robust_attention.py \
    --model_path model_with_middle_fusion.pt \
    --save_dir ./with_middle

# å¯¹æ¯”çƒ­å›¾
compare_heatmaps ./no_middle ./with_middle
```

### åœºæ™¯ 3: æ‚¨æƒ³åˆ†ææ²¡æœ‰ç»†ç²’åº¦æ³¨æ„åŠ›çš„æ¨¡å‹

**é—®é¢˜**: æ¨¡å‹åªæœ‰ `use_middle_fusion=True`ï¼Œæ²¡æœ‰ `use_fine_grained_attention`

**è§£å†³æ–¹æ¡ˆ**: ä½¿ç”¨å…¶ä»–å¯è§†åŒ–æ–¹æ³•ï¼ˆä¸æ˜¯ç»†ç²’åº¦çƒ­å›¾ï¼‰

**æ›¿ä»£æ–¹æ¡ˆ**:
1. **å…¨å±€æ³¨æ„åŠ›å¯è§†åŒ–** (å¦‚æœæ¨¡å‹æœ‰ cross-modal attention)
2. **ç‰¹å¾ç›¸ä¼¼åº¦åˆ†æ** (èŠ‚ç‚¹ç‰¹å¾ vs æ–‡æœ¬ç‰¹å¾çš„ä½™å¼¦ç›¸ä¼¼åº¦)
3. **æ¢¯åº¦å½’å› åˆ†æ** (Grad-CAM, Integrated Gradients)

---

## ğŸ¨ ä¸åŒé…ç½®çš„å¯è§†åŒ–å¯¹æ¯”

### é…ç½® A: æ— ä¸­æœŸèåˆ + æœ‰ç»†ç²’åº¦æ³¨æ„åŠ›

**ç‰¹ç‚¹**:
```
èŠ‚ç‚¹ç‰¹å¾: çº¯ç»“æ„ä¿¡æ¯
ç»†ç²’åº¦æ³¨æ„åŠ›: âœ… æœ‰
çƒ­å›¾: âœ… å¯ä»¥ç”Ÿæˆ

çƒ­å›¾ç‰¹å¾:
  â€¢ æ³¨æ„åŠ›åˆ†æ•£ï¼ˆç†µé«˜ï¼‰
  â€¢ æ— ç”¨è¯è·å¾—é«˜æƒé‡
  â€¢ æ‰€æœ‰åŸå­å¯èƒ½ç›¸åŒï¼ˆGNNè¿‡å¹³æ»‘ï¼‰
```

### é…ç½® B: æœ‰ä¸­æœŸèåˆ + æœ‰ç»†ç²’åº¦æ³¨æ„åŠ›

**ç‰¹ç‚¹**:
```
èŠ‚ç‚¹ç‰¹å¾: ç»“æ„ + æ–‡æœ¬è¯­ä¹‰
ç»†ç²’åº¦æ³¨æ„åŠ›: âœ… æœ‰
çƒ­å›¾: âœ… å¯ä»¥ç”Ÿæˆ

çƒ­å›¾ç‰¹å¾:
  â€¢ æ³¨æ„åŠ›é›†ä¸­ï¼ˆç†µä½ï¼‰
  â€¢ æ— ç”¨è¯è¢«æŠ‘åˆ¶
  â€¢ æ‰€æœ‰åŸå­ä»ç„¶ç›¸åŒï¼ˆMiddle Fusionå¹¿æ’­ï¼‰
```

### é…ç½® C: æœ‰ä¸­æœŸèåˆ + æ— ç»†ç²’åº¦æ³¨æ„åŠ›

**ç‰¹ç‚¹**:
```
èŠ‚ç‚¹ç‰¹å¾: ç»“æ„ + æ–‡æœ¬è¯­ä¹‰
ç»†ç²’åº¦æ³¨æ„åŠ›: âŒ æ— 
çƒ­å›¾: âŒ æ— æ³•ç”Ÿæˆ

æ›¿ä»£å¯è§†åŒ–:
  â€¢ å¯ä»¥åˆ†æèŠ‚ç‚¹ç‰¹å¾å’Œæ–‡æœ¬ç‰¹å¾çš„ç›¸ä¼¼åº¦
  â€¢ å¯ä»¥ä½¿ç”¨æ¢¯åº¦å½’å› æ–¹æ³•
  â€¢ ä½†æ— æ³•ç”ŸæˆåŸå­-è¯çº§åˆ«çš„çƒ­å›¾
```

---

## âœ… æ€»ç»“

### å…³é”®è¦ç‚¹

1. **çƒ­å›¾å¿…é¡»è¦æœ‰ç»†ç²’åº¦æ³¨æ„åŠ›**
   - `use_fine_grained_attention=True` æ˜¯å¿…éœ€çš„
   - è¿™æ˜¯çƒ­å›¾æ•°æ®çš„å”¯ä¸€æ¥æº

2. **ä¸­æœŸèåˆ â‰  ç»†ç²’åº¦æ³¨æ„åŠ›**
   - Middle Fusion: æ–‡æœ¬æ³¨å…¥åˆ° GNN èŠ‚ç‚¹ç‰¹å¾
   - Fine-Grained Attention: è®¡ç®—åŸå­-è¯æ³¨æ„åŠ›æƒé‡
   - ä¸¤è€…ç‹¬ç«‹ï¼Œå¯ä»¥ä»»æ„ç»„åˆ

3. **å››ç§é…ç½®å¯¹æ¯”**

| Middle Fusion | Fine-Grained Attention | èƒ½å¦ç”Ÿæˆçƒ­å›¾ | ç‰¹ç‚¹ |
|--------------|------------------------|-------------|------|
| âŒ | âŒ | âŒ ä¸èƒ½ | åŸºç¡€æ¨¡å‹ï¼Œæ— å¯è§£é‡Šæ€§ |
| âŒ | âœ… | âœ… èƒ½ | æ³¨æ„åŠ›åˆ†æ•£ï¼Œå«æ— ç”¨è¯ |
| âœ… | âŒ | âŒ ä¸èƒ½ | æ€§èƒ½å¥½ï¼Œä½†æ— çƒ­å›¾ |
| âœ… | âœ… | âœ… èƒ½ | æ³¨æ„åŠ›é›†ä¸­ï¼Œè¿‡æ»¤æ— ç”¨è¯ |

4. **æ‚¨ä¹‹å‰çœ‹åˆ°çš„çƒ­å›¾å¯¹æ¯”**
   - éƒ½éœ€è¦ `use_fine_grained_attention=True`
   - åŒºåˆ«åœ¨äº `use_middle_fusion` çš„å¼€å…³
   - æ— ä¸­æœŸèåˆ â†’ æ³¨æ„åŠ›åˆ†æ•£åˆ°æ— ç”¨è¯
   - æœ‰ä¸­æœŸèåˆ â†’ æ³¨æ„åŠ›é›†ä¸­ï¼Œè¿‡æ»¤æ— ç”¨è¯

### å®é™…å»ºè®®

**å¦‚æœæƒ³è¿›è¡Œå¯è§£é‡Šæ€§åˆ†æï¼Œæ¨èé…ç½®**:
```python
use_middle_fusion = True  # è¿‡æ»¤æ— ç”¨è¯
use_fine_grained_attention = True  # ç”Ÿæˆçƒ­å›¾
```

**å¦‚æœåªå…³å¿ƒé¢„æµ‹æ€§èƒ½ï¼Œä¸éœ€è¦è§£é‡Šæ€§**:
```python
use_middle_fusion = True  # æå‡æ€§èƒ½
use_fine_grained_attention = False  # èŠ‚çœè®¡ç®—
```

**å¦‚æœæƒ³ç ”ç©¶æ³¨æ„åŠ›æœºåˆ¶çš„åŸºç¡€è¡Œä¸º**:
```python
use_middle_fusion = False  # è§‚å¯Ÿçº¯ç»“æ„ç‰¹å¾çš„æ³¨æ„åŠ›
use_fine_grained_attention = True  # ç”Ÿæˆçƒ­å›¾
```

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- `models/alignn.py:352-450` - FineGrainedCrossModalAttention ç±»å®šä¹‰
- `models/alignn.py:556` - use_fine_grained_attention é…ç½®
- `models/alignn.py:566` - use_middle_fusion é…ç½®
- `demo_fine_grained_attention.py` - ç»†ç²’åº¦æ³¨æ„åŠ›æ¼”ç¤ºè„šæœ¬
- `MIDDLE_FUSION_COMPARISON.md` - ä¸­æœŸèåˆå¯¹æ¯”åˆ†æ

---

**æœ€ç»ˆå›ç­”æ‚¨çš„é—®é¢˜**:

âŒ **ä¸èƒ½**ã€‚æ²¡æœ‰ç»†ç²’åº¦æ³¨æ„åŠ›ï¼ˆ`use_fine_grained_attention=False`ï¼‰å°±æ— æ³•ç”ŸæˆåŸå­-è¯çº§åˆ«çš„çƒ­å›¾ï¼Œå› ä¸ºæ¨¡å‹ä¸ä¼šè®¡ç®—è¿™äº›æ³¨æ„åŠ›æƒé‡ã€‚

âœ… ä½†æ‚¨å¯ä»¥å¯¹æ¯”ï¼š
- **æ— ä¸­æœŸèåˆ** + æœ‰ç»†ç²’åº¦æ³¨æ„åŠ› vs
- **æœ‰ä¸­æœŸèåˆ** + æœ‰ç»†ç²’åº¦æ³¨æ„åŠ›

ä¸¤è€…éƒ½éœ€è¦ `use_fine_grained_attention=True`ï¼
