# 融合层位置搜索 - 快速开始

## 🎯 目标

找到最佳的融合层位置（哪些 ALIGNN 层应该使用 DynamicFusionModule）

---

## 🚀 一键运行

```bash
# 测试所有配置（包括基线）
chmod +x search_fusion_layers.sh
./search_fusion_layers.sh
```

**预计时间**: ~2 小时（6个配置 × 15-20分钟）

---

## 📊 测试配置

| 配置 | 说明 | 用途 |
|------|------|------|
| `none` | **基线**：不使用中期融合 | 对比基准 |
| `"1"` | 早期融合（第1层） | 测试早期注入 |
| `"2"` | 中期融合（第2层）| **你的原始配置** |
| `"3"` | 后期融合（第3层）| 测试后期注入 |
| `"2,3"` | 双层融合 | 测试多层融合 |
| `"1,2,3"` | 全层融合 | 测试最大融合 |

---

## 📁 输出结构

```
fusion_layer_search/
├── baseline_no_fusion/         # 基线（无融合）
│   ├── train_*.log
│   └── mbj_bandgap/
│       ├── best_val_model.pt
│       └── history_val.json
│
├── layers_1/                   # 配置1
│   ├── train_*.log
│   └── mbj_bandgap/
│       ├── best_val_model.pt
│       ├── fusion_weights.csv  ⭐ 权重日志
│       └── history_val.json
│
├── layers_2/                   # 配置2（你的原始）
├── layers_3/                   # 配置3
├── layers_2_3/                 # 配置4
├── layers_1_2_3/               # 配置5
│
└── results_summary.csv         ⭐ 汇总结果
```

---

## 🔍 查看结果

### 自动分析（推荐）

```bash
python compare_search_results.py --search_dir ./fusion_layer_search/
```

**输出内容**：
```
================================================================================
融合层位置搜索 - 结果汇总
================================================================================

🏆 按验证集 MAE 排序（越小越好):

fusion_layers  best_val_mae  best_test_mae  final_w_graph  final_w_text  ratio
          none        0.1345         0.1367            N/A           N/A    N/A
           2,3        0.1234         0.1256         0.6842        0.3158   5.33
             2        0.1256         0.1278         0.6523        0.3477   4.87
             3        0.1289         0.1301         0.7012        0.2988   6.34
         1,2,3        0.1298         0.1312         0.6234        0.3766   4.12
             1        0.1345         0.1367         0.5890        0.4110   3.43

================================================================================
✅ 最佳配置
================================================================================
Fusion Layers:    2,3
验证集 MAE:       0.1234
测试集 MAE:       0.1256
图/文本比例:      5.33x

📊 与基线对比
================================================================================

基线（无融合）MAE: 0.1345
最佳配置 (2,3)  MAE: 0.1234
相对提升: ↓ 8.25% ✅ 融合有效！

各配置相对基线的提升:
    Layers 2,3:    ↓ 8.25% (更好)
    Layers 2:      ↓ 6.62% (更好)
    Layers 3:      ↓ 4.16% (更好)
    Layers 1,2,3:  ↓ 3.49% (更好)
    Layers 1:      持平

💡 下一步建议
================================================================================

📌 Top 3 配置推荐用于阶段2:
1. Fusion Layers = 2,3 (MAE: 0.1234)
2. Fusion Layers = 2   (MAE: 0.1256)
3. Fusion Layers = 3   (MAE: 0.1289)
```

### 手动查看

```bash
# 查看汇总 CSV
cat fusion_layer_search/results_summary.csv

# 查看特定配置的训练日志
tail -f fusion_layer_search/layers_2/train_*.log

# 查看权重演化
cat fusion_layer_search/layers_2/mbj_bandgap/fusion_weights.csv
```

---

## 🎯 如何选择最佳配置

### 决策流程

```
1. 检查所有融合配置是否都优于基线？
   ├─ Yes → 融合有效，继续
   └─ No  → 检查训练是否正常

2. MAE 差异 > 5%？
   ├─ Yes → 选择 MAE 最小的
   └─ No  → 查看权重比例

3. 权重比例健康（3-10x）？
   ├─ Yes → 选择简单配置（层数少）
   └─ No  → 排除，选择健康的

4. 最终决定 ✅
```

### 判断标准

| 指标 | 优先级 | 健康范围 |
|------|--------|---------|
| **验证 MAE** | 🔴 最高 | 越小越好 |
| **vs 基线提升** | 🔴 高 | > 3% |
| **图/文本比例** | 🟡 中 | 3-10x |
| **配置简单性** | 🟢 低 | 层数越少越好 |

---

## 💡 预期结果

### 性能提升

| 对比 | 预期 | 说明 |
|------|------|------|
| 融合 vs 基线 | +3-10% | 主要收益 |
| 单层 vs 多层 | +1-5% | 次要收益 |

### 权重比例

| 配置 | 预期 w_graph | 预期 w_text | 比例 |
|------|--------------|-------------|------|
| Layer 1（早期）| 0.55-0.65 | 0.35-0.45 | 3-4x |
| Layer 2（中期）| 0.60-0.70 | 0.30-0.40 | 4-6x |
| Layer 3（后期）| 0.65-0.75 | 0.25-0.35 | 5-8x |
| Multi-layer | 0.60-0.70 | 0.30-0.40 | 4-6x |

**解释**：
- 后期层：图特征已经很强，文本影响较小
- 早期层：图特征较弱，文本影响较大
- 多层：综合效果，介于中间

---

## ⚠️ 故障排查

### Q1: 所有配置 MAE 都很接近（<1%）

**原因**：小数据集差异不明显

**解决**：
```bash
# 增加数据量和训练时间
--n_train 1000
--epochs 30
```

### Q2: 基线反而最好？

**可能原因**：
1. 训练不稳定（检查 loss 曲线）
2. 超参数不合适
3. 文本质量问题

**解决**：
```bash
# 调整学习率
--learning_rate 5e-4  # 或 2e-3

# 增加 epochs
--epochs 30
```

### Q3: 所有权重比例都异常（<2 或 >20）

**原因**：模型配置问题

**解决**：
```bash
# 调整融合模块参数
--middle_fusion_hidden_dim 256  # 增加容量
--middle_fusion_dropout 0.05    # 减少 dropout
```

---

## 🔄 如果需要重新测试

### 测试单个配置

```bash
# 只测试特定配置
./test_single_config.sh "2,3"
```

### 自定义搜索范围

编辑 `search_fusion_layers.sh`：
```bash
# 修改这一行
FUSION_LAYERS_LIST=(
    "none"     # 保留基线
    "2"        # 你想测试的
    "2,3"      # 其他配置
)
```

### 修改数据规模

```bash
# 在脚本中修改
--n_train 1000     # 更多数据（更准确）
--epochs 30        # 更多 epochs
```

---

## 📈 下一步

### 如果融合有效（相对基线提升 > 3%）

```bash
# 1. 选择 Top 1-2 配置

# 2. 进行阶段2（中等数据精细调整）
# （脚本待创建）

# 3. 或直接用最佳配置完整训练
python train_with_cross_modal_attention.py \
    --use_middle_fusion True \
    --middle_fusion_layers "2,3"  # 你的最佳配置
    --epochs 100 \
    --output_dir ./output_final/
```

### 如果融合无效（提升 < 3%）

```bash
# 检查：
1. 训练日志是否正常
2. 权重演化是否稳定
3. 文本数据质量

# 尝试：
1. 增加数据量（--n_train 1000）
2. 调整融合模块参数
3. 检查文本描述是否有意义
```

---

## 📚 相关文档

- **详细指南**: `HYPERPARAMETER_SEARCH_GUIDE.md`
- **配置分析**: `YOUR_CONFIG_ANALYSIS.md`
- **训练示例**: `TRAINING_EXAMPLES.md`

---

## 🎓 关键要点

1. ✅ **基线很重要**：必须与 `none` 对比，确认融合有效
2. ✅ **相对排名可靠**：小数据上的相对排名通常正确
3. ✅ **绝对值不可靠**：小数据的 MAE 绝对值不代表全数据性能
4. ✅ **权重比例**：图应占主导（3-10x），符合物理先验
5. ✅ **简单优先**：性能接近时，选择简单配置

---

准备好了吗？开始搜索：

```bash
./search_fusion_layers.sh
```

预计 2 小时后查看结果：
```bash
python compare_search_results.py --search_dir ./fusion_layer_search/
```

🚀 祝搜索顺利！
