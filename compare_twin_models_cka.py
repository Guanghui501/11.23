#!/usr/bin/env python
"""
åŒæ¨¡å‹CKAå¯¹æ¯”è„šæœ¬
ç”¨äºè®¡ç®—ä¸¤ä¸ªä¸åŒæ¨¡å‹ï¼ˆå¦‚baseline vs SGANetï¼‰åœ¨ç›¸åŒç‰¹å¾é˜¶æ®µçš„CKAç›¸ä¼¼åº¦
"""

import os
import argparse
import torch
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm

# è®¾ç½®ç»˜å›¾é£æ ¼
sns.set_style("whitegrid")
plt.rcParams['font.size'] = 12
plt.rcParams['figure.dpi'] = 300

# å¯¼å…¥æ¨¡å‹å’Œæ•°æ®åŠ è½½å™¨
import sys
sys.path.insert(0, os.path.dirname(__file__))
from models.alignn import ALIGNN
from train_with_cross_modal_attention import load_dataset, get_dataset_paths
from data import get_train_val_loaders


def centered_kernel_alignment(X, Y):
    """
    è®¡ç®— CKA (Centered Kernel Alignment) ç›¸ä¼¼åº¦

    Args:
        X: ç‰¹å¾çŸ©é˜µ1 [N, D1]
        Y: ç‰¹å¾çŸ©é˜µ2 [N, D2]

    Returns:
        CKA score (0-1ä¹‹é—´ï¼Œè¶Šé«˜è¶Šç›¸ä¼¼)
    """
    X = X - X.mean(axis=0)
    Y = Y - Y.mean(axis=0)
    K = X @ X.T
    L = Y @ Y.T
    hsic = np.sum(K * L)
    denom = np.sqrt(np.sum(K * K) * np.sum(L * L))
    return hsic / denom if denom > 0 else 0.0


def load_model(path, device):
    """åŠ è½½æ¨¡å‹"""
    print(f"ğŸ“¦ åŠ è½½æ¨¡å‹: {path}")
    ckpt = torch.load(path, map_location=device, weights_only=False)
    config = ckpt.get('config') or ckpt.get('model_config')
    model = ALIGNN(config)
    model.load_state_dict(ckpt['model'])
    model.to(device)
    model.eval()

    # æ‰“å°æ¨¡å‹é…ç½®
    print(f"   é…ç½®: ä¸­æœŸèåˆ={model.use_middle_fusion}, "
          f"ç»†ç²’åº¦æ³¨æ„åŠ›={model.use_fine_grained_attention}, "
          f"å…¨å±€æ³¨æ„åŠ›={model.use_cross_modal_attention}")

    return model


def extract_all_stage_features(model, loader, device, max_samples=None):
    """
    æå–æ‰€æœ‰é˜¶æ®µçš„ç‰¹å¾

    Returns:
        features_dict: {
            'graph_base': [...],
            'graph_middle': [...],
            'graph_fine': [...],
            'graph_final': [...],
            'text_base': [...],
            'text_fine': [...],
            'text_final': [...],
            'fused': [...]
        }
        targets: ç›®æ ‡å€¼
    """
    print("ğŸ”„ æå–æ‰€æœ‰é˜¶æ®µçš„ç‰¹å¾...")

    features_dict = {
        'graph_base': [],
        'graph_middle': [],
        'graph_fine': [],
        'graph_final': [],
        'text_base': [],
        'text_fine': [],
        'text_final': [],
        'fused': []
    }
    targets = []

    sample_count = 0

    with torch.no_grad():
        for batch in tqdm(loader, desc="æå–ç‰¹å¾"):
            if len(batch) == 3:
                g, text, y = batch
                lg = None
            elif len(batch) == 4:
                g, lg, text, y = batch
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„batchæ ¼å¼: {len(batch)}ä¸ªå…ƒç´ ")

            g = g.to(device)
            if lg is not None:
                lg = lg.to(device)

            # å¤„ç†text
            if isinstance(text, dict):
                text = {k: v.to(device) for k, v in text.items()}
            elif isinstance(text, (list, tuple)):
                pass
            elif torch.is_tensor(text):
                text = text.to(device)

            # æ„å»ºæ¨¡å‹è¾“å…¥
            if lg is not None:
                model_input = (g, lg, text)
            else:
                model_input = (g, text)

            # æå–æ‰€æœ‰ä¸­é—´ç‰¹å¾
            out = model(model_input, return_intermediate_features=True)

            # æå–å„é˜¶æ®µç‰¹å¾
            if 'graph_base' in out:
                features_dict['graph_base'].append(out['graph_base'].cpu().numpy())

            if 'graph_middle' in out:
                features_dict['graph_middle'].append(out['graph_middle'].cpu().numpy())

            if 'graph_fine' in out:
                features_dict['graph_fine'].append(out['graph_fine'].cpu().numpy())

            if 'graph_features' in out:
                features_dict['graph_final'].append(out['graph_features'].cpu().numpy())

            if 'text_base' in out:
                features_dict['text_base'].append(out['text_base'].cpu().numpy())

            if 'text_fine' in out:
                features_dict['text_fine'].append(out['text_fine'].cpu().numpy())

            if 'text_features' in out:
                features_dict['text_final'].append(out['text_features'].cpu().numpy())

            # èåˆç‰¹å¾
            graph_feat = out.get('graph_features')
            text_feat = out.get('text_features')
            if graph_feat is not None and text_feat is not None:
                fused = torch.cat([graph_feat, text_feat], dim=1)
                features_dict['fused'].append(fused.cpu().numpy())

            targets.append(y.cpu().numpy())

            sample_count += y.size(0)
            if max_samples and sample_count >= max_samples:
                break

    # è½¬æ¢ä¸ºnumpyæ•°ç»„
    for key in list(features_dict.keys()):
        if len(features_dict[key]) > 0:
            features_dict[key] = np.vstack(features_dict[key])
        else:
            del features_dict[key]  # åˆ é™¤ç©ºç‰¹å¾

    targets = np.concatenate(targets)

    print(f"âœ… æå–å®Œæˆ! æ ·æœ¬æ•°: {len(targets)}, ç‰¹å¾é˜¶æ®µ: {list(features_dict.keys())}")

    return features_dict, targets


def compute_twin_model_cka(features_model1, features_model2, model1_name='Model 1', model2_name='Model 2'):
    """
    è®¡ç®—ä¸¤ä¸ªæ¨¡å‹åœ¨ç›¸åŒé˜¶æ®µçš„CKAç›¸ä¼¼åº¦

    Args:
        features_model1: æ¨¡å‹1çš„ç‰¹å¾å­—å…¸
        features_model2: æ¨¡å‹2çš„ç‰¹å¾å­—å…¸
        model1_name: æ¨¡å‹1çš„åç§°
        model2_name: æ¨¡å‹2çš„åç§°

    Returns:
        cka_scores: {stage: cka_score}
    """
    print(f"\nğŸ” è®¡ç®— {model1_name} vs {model2_name} çš„CKAç›¸ä¼¼åº¦...")

    # æ‰¾åˆ°ä¸¤ä¸ªæ¨¡å‹å…±æœ‰çš„ç‰¹å¾é˜¶æ®µ
    common_stages = set(features_model1.keys()) & set(features_model2.keys())

    if not common_stages:
        print("âš ï¸  ä¸¤ä¸ªæ¨¡å‹æ²¡æœ‰å…±åŒçš„ç‰¹å¾é˜¶æ®µ!")
        return {}

    print(f"   å…±åŒé˜¶æ®µ: {sorted(common_stages)}")

    cka_scores = {}

    for stage in sorted(common_stages):
        print(f"   è®¡ç®—é˜¶æ®µ: {stage}")
        feat1 = features_model1[stage]
        feat2 = features_model2[stage]

        # ç¡®ä¿æ ·æœ¬æ•°ä¸€è‡´
        min_samples = min(len(feat1), len(feat2))
        feat1 = feat1[:min_samples]
        feat2 = feat2[:min_samples]

        # è®¡ç®—CKA
        cka = centered_kernel_alignment(feat1, feat2)
        cka_scores[stage] = cka

        print(f"      {stage}: {cka:.4f}")

    return cka_scores


def visualize_cka_scores(cka_scores, model1_name, model2_name, save_dir):
    """
    å¯è§†åŒ–CKAåˆ†æ•°

    Args:
        cka_scores: {stage: cka_score}
        model1_name: æ¨¡å‹1åç§°
        model2_name: æ¨¡å‹2åç§°
        save_dir: ä¿å­˜ç›®å½•
    """
    print("\nğŸ“Š ç”ŸæˆCKAåˆ†æ•°å¯è§†åŒ–...")

    if not cka_scores:
        print("âš ï¸  æ²¡æœ‰CKAåˆ†æ•°å¯è§†åŒ–")
        return

    # å‡†å¤‡æ•°æ®
    stages = list(cka_scores.keys())
    scores = list(cka_scores.values())

    # åˆ›å»ºå›¾å½¢
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))

    # å­å›¾1: æŸ±çŠ¶å›¾
    colors = plt.cm.RdYlGn([s for s in scores])
    bars = ax1.bar(range(len(stages)), scores, color=colors, alpha=0.8, edgecolor='black', linewidth=1.5)
    ax1.set_xticks(range(len(stages)))
    ax1.set_xticklabels(stages, rotation=45, ha='right')
    ax1.set_ylabel('CKA Similarity Score', fontweight='bold', fontsize=12)
    ax1.set_title(f'CKA Similarity: {model1_name} vs {model2_name}',
                 fontweight='bold', fontsize=14, pad=15)
    ax1.set_ylim([0, 1.0])
    ax1.grid(axis='y', alpha=0.3, linestyle='--')
    ax1.axhline(y=0.9, color='green', linestyle='--', linewidth=1, alpha=0.5, label='High (0.9)')
    ax1.axhline(y=0.7, color='orange', linestyle='--', linewidth=1, alpha=0.5, label='Moderate (0.7)')
    ax1.axhline(y=0.5, color='red', linestyle='--', linewidth=1, alpha=0.5, label='Low (0.5)')
    ax1.legend(loc='lower right', fontsize=10)

    # æ ‡æ³¨æ•°å€¼
    for i, (bar, score) in enumerate(zip(bars, scores)):
        height = bar.get_height()
        ax1.text(bar.get_x() + bar.get_width()/2., height + 0.02,
                f'{score:.3f}',
                ha='center', va='bottom', fontweight='bold', fontsize=10)

    # å­å›¾2: é˜¶æ®µæ¼”å˜çº¿å›¾
    stage_order = ['graph_base', 'graph_middle', 'graph_fine', 'graph_final',
                   'text_base', 'text_fine', 'text_final', 'fused']
    ordered_stages = [s for s in stage_order if s in stages]
    ordered_scores = [cka_scores[s] for s in ordered_stages]

    ax2.plot(range(len(ordered_stages)), ordered_scores, 'o-',
            linewidth=2, markersize=10, color='steelblue',
            markeredgecolor='black', markeredgewidth=1.5)
    ax2.set_xticks(range(len(ordered_stages)))
    ax2.set_xticklabels(ordered_stages, rotation=45, ha='right')
    ax2.set_ylabel('CKA Similarity Score', fontweight='bold', fontsize=12)
    ax2.set_title('CKA Evolution Across Processing Stages',
                 fontweight='bold', fontsize=14, pad=15)
    ax2.set_ylim([0, 1.0])
    ax2.grid(True, alpha=0.3, linestyle='--')
    ax2.axhline(y=0.9, color='green', linestyle='--', linewidth=1, alpha=0.5)
    ax2.axhline(y=0.7, color='orange', linestyle='--', linewidth=1, alpha=0.5)
    ax2.axhline(y=0.5, color='red', linestyle='--', linewidth=1, alpha=0.5)

    # æ ‡æ³¨æ•°å€¼
    for i, score in enumerate(ordered_scores):
        ax2.text(i, score + 0.02, f'{score:.3f}',
                ha='center', va='bottom', fontweight='bold', fontsize=9)

    plt.tight_layout()
    save_path = os.path.join(save_dir, 'twin_models_cka_comparison.png')
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"âœ… CKAå¯è§†åŒ–å·²ä¿å­˜: {save_path}")
    plt.close()


def generate_cka_report(cka_scores, model1_name, model2_name, save_dir):
    """
    ç”ŸæˆCKAå¯¹æ¯”æŠ¥å‘Š

    Args:
        cka_scores: {stage: cka_score}
        model1_name: æ¨¡å‹1åç§°
        model2_name: æ¨¡å‹2åç§°
        save_dir: ä¿å­˜ç›®å½•
    """
    print("\nğŸ“ ç”ŸæˆCKAå¯¹æ¯”æŠ¥å‘Š...")

    report_lines = []
    report_lines.append("=" * 80)
    report_lines.append(f"Twin Model CKA Similarity Report")
    report_lines.append(f"Model 1: {model1_name}")
    report_lines.append(f"Model 2: {model2_name}")
    report_lines.append("=" * 80)
    report_lines.append("")

    # 1. æ•´ä½“ç»Ÿè®¡
    scores = list(cka_scores.values())
    report_lines.append("ğŸ“Š Overall Statistics:")
    report_lines.append(f"  â€¢ Mean CKA Score: {np.mean(scores):.4f}")
    report_lines.append(f"  â€¢ Median CKA Score: {np.median(scores):.4f}")
    report_lines.append(f"  â€¢ Min CKA Score: {np.min(scores):.4f} (Stage: {min(cka_scores, key=cka_scores.get)})")
    report_lines.append(f"  â€¢ Max CKA Score: {np.max(scores):.4f} (Stage: {max(cka_scores, key=cka_scores.get)})")
    report_lines.append(f"  â€¢ Std CKA Score: {np.std(scores):.4f}")
    report_lines.append("")

    # 2. å„é˜¶æ®µè¯¦ç»†åˆ†æ•°
    report_lines.append("ğŸ”¬ Stage-by-Stage CKA Scores:")
    report_lines.append("")

    stage_descriptions = {
        'graph_base': 'Graph Base (GCNåï¼Œæ³¨æ„åŠ›å‰)',
        'graph_middle': 'Graph Middle (ä¸­æœŸèåˆå)',
        'graph_fine': 'Graph Fine (ç»†ç²’åº¦æ³¨æ„åŠ›å)',
        'graph_final': 'Graph Final (æœ€ç»ˆå›¾ç‰¹å¾)',
        'text_base': 'Text Base (åˆå§‹æ–‡æœ¬ç‰¹å¾)',
        'text_fine': 'Text Fine (ç»†ç²’åº¦æ³¨æ„åŠ›å)',
        'text_final': 'Text Final (æœ€ç»ˆæ–‡æœ¬ç‰¹å¾)',
        'fused': 'Fused (å›¾+æ–‡æœ¬èåˆç‰¹å¾)'
    }

    for stage in sorted(cka_scores.keys()):
        score = cka_scores[stage]
        desc = stage_descriptions.get(stage, stage)

        # è§£é‡Šåˆ†æ•°
        if score > 0.9:
            interpretation = "æé«˜ç›¸ä¼¼åº¦ - ä¸¤ä¸ªæ¨¡å‹å­¦åˆ°äº†å‡ ä¹ç›¸åŒçš„è¡¨ç¤º"
        elif score > 0.7:
            interpretation = "é«˜ç›¸ä¼¼åº¦ - ä¸¤ä¸ªæ¨¡å‹å­¦åˆ°äº†ç›¸ä¼¼çš„ä¸»è¦æ¨¡å¼"
        elif score > 0.5:
            interpretation = "ä¸­ç­‰ç›¸ä¼¼åº¦ - ä¸¤ä¸ªæ¨¡å‹æœ‰æ˜¾è‘—å·®å¼‚"
        else:
            interpretation = "ä½ç›¸ä¼¼åº¦ - ä¸¤ä¸ªæ¨¡å‹å­¦åˆ°äº†éå¸¸ä¸åŒçš„è¡¨ç¤º"

        report_lines.append(f"  â€¢ {desc}")
        report_lines.append(f"    Stage: {stage}")
        report_lines.append(f"    CKA Score: {score:.4f}")
        report_lines.append(f"    è§£é‡Š: {interpretation}")
        report_lines.append("")

    # 3. å…³é”®å‘ç°
    report_lines.append("ğŸ” Key Findings:")

    # æ‰¾å‡ºæœ€ç›¸ä¼¼å’Œæœ€ä¸ç›¸ä¼¼çš„é˜¶æ®µ
    max_stage = max(cka_scores, key=cka_scores.get)
    min_stage = min(cka_scores, key=cka_scores.get)

    report_lines.append(f"  â€¢ æœ€ç›¸ä¼¼é˜¶æ®µ: {max_stage} (CKA = {cka_scores[max_stage]:.4f})")
    report_lines.append(f"    â†’ ä¸¤ä¸ªæ¨¡å‹åœ¨æ­¤é˜¶æ®µçš„è¡¨ç¤ºæœ€æ¥è¿‘")
    report_lines.append("")
    report_lines.append(f"  â€¢ æœ€ä¸ç›¸ä¼¼é˜¶æ®µ: {min_stage} (CKA = {cka_scores[min_stage]:.4f})")
    report_lines.append(f"    â†’ ä¸¤ä¸ªæ¨¡å‹åœ¨æ­¤é˜¶æ®µçš„å·®å¼‚æœ€å¤§")
    report_lines.append("")

    # èåˆæ•ˆæœåˆ†æ
    if 'graph_base' in cka_scores and 'graph_final' in cka_scores:
        base_cka = cka_scores['graph_base']
        final_cka = cka_scores['graph_final']
        delta = final_cka - base_cka

        report_lines.append("  â€¢ èåˆè¿‡ç¨‹çš„å½±å“:")
        report_lines.append(f"    Graph Base CKA: {base_cka:.4f}")
        report_lines.append(f"    Graph Final CKA: {final_cka:.4f}")
        report_lines.append(f"    å˜åŒ–: {delta:+.4f}")

        if delta > 0.05:
            report_lines.append(f"    â†’ èåˆè¿‡ç¨‹ä½¿ä¸¤ä¸ªæ¨¡å‹çš„è¡¨ç¤ºæ›´åŠ ç›¸ä¼¼")
        elif delta < -0.05:
            report_lines.append(f"    â†’ èåˆè¿‡ç¨‹å¢åŠ äº†ä¸¤ä¸ªæ¨¡å‹çš„å·®å¼‚")
        else:
            report_lines.append(f"    â†’ èåˆè¿‡ç¨‹å¯¹ç›¸ä¼¼åº¦å½±å“è¾ƒå°")
        report_lines.append("")

    # 4. å»ºè®®
    report_lines.append("ğŸ’¡ Insights and Recommendations:")
    avg_cka = np.mean(scores)

    if avg_cka > 0.85:
        report_lines.append("  â€¢ ä¸¤ä¸ªæ¨¡å‹æ•´ä½“ç›¸ä¼¼åº¦å¾ˆé«˜")
        report_lines.append("  â€¢ å¯èƒ½åŸå› : æ¨¡å‹æ¶æ„æ¥è¿‘ï¼Œè®­ç»ƒæ•°æ®ç›¸åŒï¼Œèåˆæœºåˆ¶å½±å“æœ‰é™")
        report_lines.append("  â€¢ å»ºè®®: å¦‚æœå¸Œæœ›å¢åŠ å¤šæ ·æ€§ï¼Œå¯ä»¥å°è¯•æ›´å¼ºçš„èåˆæœºåˆ¶")
    elif avg_cka > 0.65:
        report_lines.append("  â€¢ ä¸¤ä¸ªæ¨¡å‹ä¿æŒäº†é€‚åº¦çš„ç›¸ä¼¼æ€§å’Œå·®å¼‚æ€§")
        report_lines.append("  â€¢ èåˆæœºåˆ¶å¸¦æ¥äº†å¯è§‚å¯Ÿçš„å˜åŒ–ï¼Œä½†ä¿ç•™äº†åŸºç¡€è¡¨ç¤º")
        report_lines.append("  â€¢ å»ºè®®: å½“å‰é…ç½®è¾ƒä¸ºåˆç†ï¼Œå¯ä»¥åˆ†æå…·ä½“é˜¶æ®µçš„å·®å¼‚æ¥ä¼˜åŒ–")
    else:
        report_lines.append("  â€¢ ä¸¤ä¸ªæ¨¡å‹çš„è¡¨ç¤ºå·®å¼‚è¾ƒå¤§")
        report_lines.append("  â€¢ å¯èƒ½åŸå› : èåˆæœºåˆ¶å¤§å¹…æ”¹å˜äº†ç‰¹å¾ç©ºé—´ï¼Œæˆ–è®­ç»ƒä¸ç¨³å®š")
        report_lines.append("  â€¢ å»ºè®®: æ£€æŸ¥è®­ç»ƒè¿‡ç¨‹ï¼Œç¡®ä¿æ¨¡å‹æ”¶æ•›ï¼›åˆ†ææ˜¯å¦æœ‰ä¿¡æ¯æŸå¤±")

    report_lines.append("")
    report_lines.append("=" * 80)

    # ä¿å­˜æŠ¥å‘Š
    report_text = "\n".join(report_lines)
    save_path = os.path.join(save_dir, 'twin_models_cka_report.txt')
    with open(save_path, 'w', encoding='utf-8') as f:
        f.write(report_text)

    print(f"âœ… CKAæŠ¥å‘Šå·²ä¿å­˜: {save_path}")
    print("\n" + report_text)

    # ä¿å­˜CSV
    df = pd.DataFrame([
        {'Stage': stage, 'CKA_Score': score}
        for stage, score in sorted(cka_scores.items())
    ])
    csv_path = os.path.join(save_dir, 'twin_models_cka_scores.csv')
    df.to_csv(csv_path, index=False)
    print(f"âœ… CKAåˆ†æ•°CSVå·²ä¿å­˜: {csv_path}")


def main():
    parser = argparse.ArgumentParser(description='åŒæ¨¡å‹CKAç›¸ä¼¼åº¦å¯¹æ¯”')
    parser.add_argument('--ckpt_model1', type=str, required=True,
                       help='æ¨¡å‹1çš„checkpointè·¯å¾„ (å¦‚baseline)')
    parser.add_argument('--ckpt_model2', type=str, required=True,
                       help='æ¨¡å‹2çš„checkpointè·¯å¾„ (å¦‚SGANet)')
    parser.add_argument('--model1_name', type=str, default='Model 1',
                       help='æ¨¡å‹1çš„åç§°')
    parser.add_argument('--model2_name', type=str, default='Model 2',
                       help='æ¨¡å‹2çš„åç§°')
    parser.add_argument('--dataset', type=str, required=True,
                       help='æ•°æ®é›†ç±»å‹')
    parser.add_argument('--property', type=str, required=True,
                       help='ç›®æ ‡å±æ€§')
    parser.add_argument('--root_dir', type=str,
                       default='/public/home/ghzhang/crysmmnet-main/dataset',
                       help='æ•°æ®é›†æ ¹ç›®å½•')
    parser.add_argument('--batch_size', type=int, default=32,
                       help='æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--max_samples', type=int, default=500,
                       help='æœ€å¤§æ ·æœ¬æ•°')
    parser.add_argument('--save_dir', type=str, default='./twin_cka_comparison',
                       help='ç»“æœä¿å­˜ç›®å½•')
    args = parser.parse_args()

    # åˆ›å»ºä¿å­˜ç›®å½•
    os.makedirs(args.save_dir, exist_ok=True)

    # è®¾ç½®è®¾å¤‡
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ–¥ï¸  ä½¿ç”¨è®¾å¤‡: {device}\n")

    # åŠ è½½æ¨¡å‹1
    print("=" * 80)
    model1 = load_model(args.ckpt_model1, device)

    # åŠ è½½æ¨¡å‹2
    print("=" * 80)
    model2 = load_model(args.ckpt_model2, device)
    print("=" * 80)

    # åŠ è½½æ•°æ®é›†
    print(f"\nğŸ”„ åŠ è½½æ•°æ®é›†: {args.dataset} - {args.property}")

    try:
        # è·å–æ•°æ®é›†è·¯å¾„
        cif_dir, id_prop_file = get_dataset_paths(args.root_dir, args.dataset, args.property)

        # åŠ è½½æ•°æ®é›†
        df = load_dataset(cif_dir, id_prop_file, args.dataset, args.property)
        print(f"âœ… åŠ è½½æ•°æ®é›†: {len(df)} æ ·æœ¬")

        # é‡‡æ ·
        if args.max_samples and len(df) > args.max_samples:
            print(f"âš ï¸  æ•°æ®é›†è¿‡å¤§ï¼Œéšæœºé‡‡æ · {args.max_samples} æ ·æœ¬")
            import random
            random.seed(42)
            df = random.sample(df, args.max_samples)

        # è·å–æ¨¡å‹1çš„é…ç½®
        config = model1.config if hasattr(model1, 'config') else None
        if config is None:
            # å°è¯•ä»checkpointåŠ è½½
            ckpt = torch.load(args.ckpt_model1, map_location='cpu', weights_only=False)
            config = ckpt.get('config') or ckpt.get('model_config')

        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        train_loader, val_loader, test_loader, _ = get_train_val_loaders(
            dataset='user_data',
            dataset_array=df,
            target='target',
            n_train=None,
            n_val=None,
            n_test=None,
            train_ratio=0.8,
            val_ratio=0.1,
            test_ratio=0.1,
            batch_size=args.batch_size,
            atom_features=config.atom_features if hasattr(config, 'atom_features') else 'cgcnn',
            neighbor_strategy='k-nearest',
            line_graph=config.line_graph if hasattr(config, 'line_graph') else True,
            split_seed=42,
            workers=0,
            pin_memory=False,
            save_dataloader=False,
            filename='temp_twin_cka',
            id_tag='jid',
            use_canonize=True,
            cutoff=8.0,
            max_neighbors=12,
            output_dir=args.save_dir
        )

        print(f"âœ… æµ‹è¯•é›†æ ·æœ¬æ•°: {len(test_loader.dataset)}")

    except Exception as e:
        print(f"âŒ åŠ è½½æ•°æ®é›†å¤±è´¥: {e}")
        raise

    # æå–æ¨¡å‹1çš„ç‰¹å¾
    print("\n" + "=" * 80)
    print(f"æå– {args.model1_name} çš„ç‰¹å¾")
    print("=" * 80)
    features_model1, targets1 = extract_all_stage_features(
        model1, test_loader, device, max_samples=args.max_samples
    )

    # æå–æ¨¡å‹2çš„ç‰¹å¾
    print("\n" + "=" * 80)
    print(f"æå– {args.model2_name} çš„ç‰¹å¾")
    print("=" * 80)
    features_model2, targets2 = extract_all_stage_features(
        model2, test_loader, device, max_samples=args.max_samples
    )

    # è®¡ç®—CKAç›¸ä¼¼åº¦
    print("\n" + "=" * 80)
    cka_scores = compute_twin_model_cka(
        features_model1, features_model2,
        args.model1_name, args.model2_name
    )

    # å¯è§†åŒ–
    visualize_cka_scores(cka_scores, args.model1_name, args.model2_name, args.save_dir)

    # ç”ŸæˆæŠ¥å‘Š
    generate_cka_report(cka_scores, args.model1_name, args.model2_name, args.save_dir)

    print(f"\nğŸ‰ åˆ†æå®Œæˆ! ç»“æœä¿å­˜åœ¨: {args.save_dir}")


if __name__ == '__main__':
    main()
