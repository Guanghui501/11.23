#!/usr/bin/env python
"""
ä¸­æœŸèåˆç‰¹å¾ç©ºé—´å¯è§†åŒ– - æŒ‰æ™¶ç³»èšç±»åˆ†æ
å¯¹æ¯”æœ‰/æ— ä¸­æœŸèåˆçš„ç‰¹å¾èšç±»è´¨é‡

ä½¿ç”¨æ–¹æ³•:
    python visualize_middle_fusion_clustering.py \
        --checkpoint_without_fusion model_no_fusion.pth \
        --checkpoint_with_fusion model_with_fusion.pth \
        --data_dir /path/to/dataset \
        --output_dir fusion_clustering_analysis
"""

import os
import argparse
import numpy as np
import pandas as pd
import torch
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

# é™ç»´ç®—æ³•
from sklearn.manifold import TSNE
from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score

try:
    import umap
    UMAP_AVAILABLE = True
except ImportError:
    UMAP_AVAILABLE = False
    print("âš ï¸  UMAPæœªå®‰è£…ï¼Œå°†ä»…ä½¿ç”¨t-SNE")

# å¯¼å…¥æ•°æ®å’Œæ¨¡å‹
from jarvis.core.atoms import Atoms
from data import get_train_val_loaders
from models.alignn import ALIGNN
from config import TrainingConfig

# è®¾ç½®ç»˜å›¾é£æ ¼
sns.set_style("whitegrid")
plt.rcParams['font.size'] = 11
plt.rcParams['axes.labelsize'] = 12
plt.rcParams['axes.titlesize'] = 13
plt.rcParams['figure.titlesize'] = 15
plt.rcParams['legend.fontsize'] = 10


# æ™¶ç³»å®šä¹‰
CRYSTAL_SYSTEMS = {
    'cubic': 'ç«‹æ–¹',
    'hexagonal': 'å…­æ–¹',
    'trigonal': 'ä¸‰æ–¹',
    'tetragonal': 'å››æ–¹',
    'orthorhombic': 'æ­£äº¤',
    'monoclinic': 'å•æ–œ',
    'triclinic': 'ä¸‰æ–œ'
}

CRYSTAL_SYSTEM_COLORS = {
    'cubic': '#e74c3c',        # çº¢è‰²
    'hexagonal': '#3498db',    # è“è‰²
    'trigonal': '#2ecc71',     # ç»¿è‰²
    'tetragonal': '#f39c12',   # æ©™è‰²
    'orthorhombic': '#9b59b6', # ç´«è‰²
    'monoclinic': '#1abc9c',   # é’è‰²
    'triclinic': '#e67e22'     # æ·±æ©™è‰²
}


def load_model(checkpoint_path, device='cpu'):
    """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
    print(f"ğŸ“‚ åŠ è½½æ¨¡å‹: {checkpoint_path}")
    checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)

    model_config = checkpoint.get('config', None)
    if model_config is None:
        raise ValueError("Checkpointä¸­æœªæ‰¾åˆ°æ¨¡å‹é…ç½®")

    model = ALIGNN(model_config)
    model.load_state_dict(checkpoint['model'])
    model.eval()
    model.to(device)

    # æ‰“å°ä¸­æœŸèåˆé…ç½®
    use_middle = model_config.use_middle_fusion if hasattr(model_config, 'use_middle_fusion') else False
    layers = model_config.middle_fusion_layers if hasattr(model_config, 'middle_fusion_layers') else 'N/A'
    print(f"   ä¸­æœŸèåˆ: {use_middle}")
    if use_middle:
        print(f"   èåˆå±‚: {layers}")

    return model, model_config


def extract_features_with_crystal_system(model, data_loader, cif_dir, device='cpu'):
    """
    æå–ç‰¹å¾å¹¶è·å–æ™¶ç³»ä¿¡æ¯

    Returns:
        features: ç‰¹å¾çŸ©é˜µ [n_samples, n_features]
        crystal_systems: æ™¶ç³»åˆ—è¡¨
        targets: ç›®æ ‡å€¼
        sample_ids: æ ·æœ¬ID
    """
    model.eval()
    features_list = []
    crystal_systems = []
    targets_list = []
    sample_ids = []

    print("ğŸ”„ æå–ç‰¹å¾å’Œæ™¶ç³»ä¿¡æ¯...")

    with torch.no_grad():
        for batch_idx, batch in enumerate(tqdm(data_loader, desc="å¤„ç†æ‰¹æ¬¡")):
            try:
                # è§£åŒ…batch
                if len(batch) == 4:
                    g, lg, text, target = batch
                    model_input = (g.to(device), lg.to(device), text)
                else:
                    g, text, target = batch
                    model_input = (g.to(device), text)

                # å‰å‘ä¼ æ’­è·å–ç‰¹å¾
                output = model(model_input, return_features=True)

                # æå–èåˆç‰¹å¾
                if isinstance(output, dict):
                    if 'fused_features' in output:
                        feat = output['fused_features']
                    elif 'graph_features' in output:
                        feat = output['graph_features']
                    else:
                        # å°è¯•ä»è¾“å‡ºä¸­è·å–æœ€åçš„ç‰¹å¾
                        feat = output.get('features', None)
                        if feat is None:
                            print(f"âš ï¸  Batch {batch_idx}: æ— æ³•æå–ç‰¹å¾")
                            continue
                else:
                    # å¦‚æœè¿”å›çš„ä¸æ˜¯å­—å…¸ï¼Œå°è¯•ç›´æ¥ä½¿ç”¨
                    feat = output

                features_list.append(feat.cpu().numpy())
                targets_list.append(target.cpu().numpy())

                # è·å–æ ·æœ¬IDå’Œæ™¶ç³»ï¼ˆä»graphä¸­ï¼‰
                batch_crystal_systems = []
                for i in range(g.batch_size):
                    try:
                        # å°è¯•ä»graphçš„èŠ‚ç‚¹æ•°æ®ä¸­è·å–ID
                        if hasattr(g, 'ndata') and 'id' in g.ndata:
                            sample_id = g.ndata['id'][i].item()
                        else:
                            sample_id = f"sample_{batch_idx}_{i}"

                        sample_ids.append(sample_id)

                        # ä»CIFæ–‡ä»¶è¯»å–æ™¶ç³»
                        if cif_dir and os.path.exists(cif_dir):
                            cif_file = os.path.join(cif_dir, f"{sample_id}.cif")
                            if os.path.exists(cif_file):
                                atoms = Atoms.from_cif(cif_file)
                                crystal_system = atoms.lattice.lattice_system
                                batch_crystal_systems.append(crystal_system)
                            else:
                                batch_crystal_systems.append('unknown')
                        else:
                            batch_crystal_systems.append('unknown')
                    except Exception as e:
                        batch_crystal_systems.append('unknown')
                        sample_ids.append(f"sample_{batch_idx}_{i}")

                crystal_systems.extend(batch_crystal_systems)

            except Exception as e:
                print(f"âš ï¸  å¤„ç†batch {batch_idx}æ—¶å‡ºé”™: {e}")
                continue

    # åˆå¹¶æ‰€æœ‰ç‰¹å¾
    features = np.vstack(features_list)
    targets = np.concatenate(targets_list)

    print(f"âœ… æå–å®Œæˆ:")
    print(f"   ç‰¹å¾ç»´åº¦: {features.shape}")
    print(f"   æ ·æœ¬æ•°: {len(crystal_systems)}")
    print(f"   æ™¶ç³»åˆ†å¸ƒ:")
    for cs in set(crystal_systems):
        count = crystal_systems.count(cs)
        print(f"     {CRYSTAL_SYSTEMS.get(cs, cs)}: {count}")

    return features, crystal_systems, targets, sample_ids


def compute_clustering_metrics(features, labels):
    """è®¡ç®—èšç±»è´¨é‡æŒ‡æ ‡"""
    # å°†å­—ç¬¦ä¸²æ ‡ç­¾è½¬ä¸ºæ•°å€¼
    unique_labels = list(set(labels))
    label_to_int = {label: i for i, label in enumerate(unique_labels)}
    numeric_labels = np.array([label_to_int[label] for label in labels])

    # è¿‡æ»¤æ‰unknownæ ‡ç­¾
    valid_mask = np.array(labels) != 'unknown'
    if valid_mask.sum() < 2:
        return {'silhouette': np.nan, 'davies_bouldin': np.nan, 'calinski_harabasz': np.nan}

    features_valid = features[valid_mask]
    labels_valid = numeric_labels[valid_mask]

    # ç¡®ä¿è‡³å°‘æœ‰2ä¸ªç±»åˆ«
    if len(np.unique(labels_valid)) < 2:
        return {'silhouette': np.nan, 'davies_bouldin': np.nan, 'calinski_harabasz': np.nan}

    metrics = {}
    try:
        metrics['silhouette'] = silhouette_score(features_valid, labels_valid)
    except:
        metrics['silhouette'] = np.nan

    try:
        metrics['davies_bouldin'] = davies_bouldin_score(features_valid, labels_valid)
    except:
        metrics['davies_bouldin'] = np.nan

    try:
        metrics['calinski_harabasz'] = calinski_harabasz_score(features_valid, labels_valid)
    except:
        metrics['calinski_harabasz'] = np.nan

    return metrics


def apply_reduction(features, method='tsne', n_components=2):
    """é™ç»´"""
    print(f"ğŸ”„ åº”ç”¨{method.upper()}é™ç»´...")

    if method == 'tsne':
        reducer = TSNE(
            n_components=n_components,
            perplexity=min(30, len(features) - 1),
            random_state=42,
            max_iter=1000
        )
    elif method == 'umap' and UMAP_AVAILABLE:
        reducer = umap.UMAP(
            n_components=n_components,
            n_neighbors=min(15, len(features) - 1),
            min_dist=0.1,
            random_state=42
        )
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„é™ç»´æ–¹æ³•: {method}")

    embedded = reducer.fit_transform(features)
    print(f"âœ… é™ç»´å®Œæˆ: {embedded.shape}")

    return embedded


def plot_comparison(embedded_without, embedded_with, crystal_systems,
                   metrics_without, metrics_with, output_path):
    """
    åˆ›å»ºå¯¹æ¯”å›¾ï¼šæœ‰æ— ä¸­æœŸèåˆçš„ç‰¹å¾èšç±»å¯¹æ¯”
    """
    fig, axes = plt.subplots(1, 2, figsize=(16, 7))

    # è¿‡æ»¤æ‰unknownçš„æ ·æœ¬ç”¨äºç»˜å›¾
    valid_mask = np.array(crystal_systems) != 'unknown'

    for idx, (embedded, metrics, title) in enumerate([
        (embedded_without, metrics_without, 'æ— ä¸­æœŸèåˆ'),
        (embedded_with, metrics_with, 'æœ‰ä¸­æœŸèåˆ')
    ]):
        ax = axes[idx]

        # ç»˜åˆ¶æ¯ä¸ªæ™¶ç³»
        for cs in set(crystal_systems):
            if cs == 'unknown':
                continue

            mask = (np.array(crystal_systems) == cs) & valid_mask
            if mask.sum() == 0:
                continue

            ax.scatter(
                embedded[mask, 0],
                embedded[mask, 1],
                c=CRYSTAL_SYSTEM_COLORS.get(cs, 'gray'),
                label=CRYSTAL_SYSTEMS.get(cs, cs),
                alpha=0.6,
                s=30,
                edgecolors='white',
                linewidths=0.5
            )

        ax.set_xlabel('ç»´åº¦ 1', fontsize=12)
        ax.set_ylabel('ç»´åº¦ 2', fontsize=12)
        ax.set_title(f'{title}\n' +
                    f'Silhouette: {metrics["silhouette"]:.3f} | ' +
                    f'DB: {metrics["davies_bouldin"]:.3f} | ' +
                    f'CH: {metrics["calinski_harabasz"]:.1f}',
                    fontsize=13, pad=15)
        ax.legend(loc='best', framealpha=0.9, fontsize=10)
        ax.grid(True, alpha=0.3)

    plt.suptitle('ç‰¹å¾ç©ºé—´èšç±»å¯¹æ¯” - æŒ‰æ™¶ç³»åˆ†ç»„', fontsize=16, y=0.98)
    plt.tight_layout()
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f"âœ… å›¾åƒå·²ä¿å­˜: {output_path}")
    plt.close()


def plot_metrics_comparison(metrics_without, metrics_with, output_path):
    """ç»˜åˆ¶èšç±»æŒ‡æ ‡å¯¹æ¯”æŸ±çŠ¶å›¾"""
    fig, axes = plt.subplots(1, 3, figsize=(15, 4))

    metric_names = ['Silhouette Score', 'Davies-Bouldin Index', 'Calinski-Harabasz Score']
    metric_keys = ['silhouette', 'davies_bouldin', 'calinski_harabasz']

    colors = ['#3498db', '#e74c3c']

    for idx, (name, key) in enumerate(zip(metric_names, metric_keys)):
        ax = axes[idx]
        values = [metrics_without[key], metrics_with[key]]
        bars = ax.bar(['æ— ä¸­æœŸèåˆ', 'æœ‰ä¸­æœŸèåˆ'], values, color=colors, alpha=0.7, edgecolor='black')

        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar in bars:
            height = bar.get_height()
            if not np.isnan(height):
                ax.text(bar.get_x() + bar.get_width()/2., height,
                       f'{height:.3f}',
                       ha='center', va='bottom', fontsize=11, fontweight='bold')

        ax.set_ylabel(name, fontsize=11)
        ax.set_title(name, fontsize=12, pad=10)
        ax.grid(True, axis='y', alpha=0.3)

        # Davies-Bouldin: è¶Šä½è¶Šå¥½
        if key == 'davies_bouldin':
            if values[1] < values[0]:
                ax.set_facecolor('#eafaf1')  # ç»¿è‰²èƒŒæ™¯è¡¨ç¤ºæ”¹è¿›

    plt.suptitle('èšç±»è´¨é‡æŒ‡æ ‡å¯¹æ¯”\n(Silhouetteå’ŒCHè¶Šé«˜è¶Šå¥½ï¼ŒDBè¶Šä½è¶Šå¥½)', fontsize=14, y=1.02)
    plt.tight_layout()
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f"âœ… æŒ‡æ ‡å¯¹æ¯”å›¾å·²ä¿å­˜: {output_path}")
    plt.close()


def main():
    parser = argparse.ArgumentParser(description='ä¸­æœŸèåˆç‰¹å¾èšç±»å¯è§†åŒ–')
    parser.add_argument('--checkpoint_without_fusion', type=str, required=True,
                       help='æ— ä¸­æœŸèåˆçš„æ¨¡å‹checkpoint')
    parser.add_argument('--checkpoint_with_fusion', type=str, required=True,
                       help='æœ‰ä¸­æœŸèåˆçš„æ¨¡å‹checkpoint')
    parser.add_argument('--data_dir', type=str, required=True,
                       help='æ•°æ®é›†ç›®å½•ï¼ˆåŒ…å«CIFæ–‡ä»¶ï¼‰')
    parser.add_argument('--dataset', type=str, default='jarvis',
                       help='æ•°æ®é›†ç±»å‹')
    parser.add_argument('--property', type=str, default='mbj_bandgap',
                       help='ç›®æ ‡å±æ€§')
    parser.add_argument('--n_samples', type=int, default=1000,
                       help='ç”¨äºå¯è§†åŒ–çš„æ ·æœ¬æ•°é‡')
    parser.add_argument('--reduction_method', type=str, default='tsne',
                       choices=['tsne', 'umap'], help='é™ç»´æ–¹æ³•')
    parser.add_argument('--output_dir', type=str, default='fusion_clustering_results',
                       help='è¾“å‡ºç›®å½•')
    parser.add_argument('--device', type=str, default='cuda' if torch.cuda.is_available() else 'cpu',
                       help='è®¾å¤‡')

    args = parser.parse_args()

    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path(args.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    print("=" * 80)
    print("ä¸­æœŸèåˆç‰¹å¾ç©ºé—´èšç±»åˆ†æ")
    print("=" * 80)

    # æ„å»ºCIFç›®å½•è·¯å¾„
    cif_dir = os.path.join(args.data_dir, f'{args.dataset}/{args.property}/cif/')

    # åŠ è½½æ•°æ®ï¼ˆä½¿ç”¨æµ‹è¯•é›†ï¼‰
    print("\nğŸ“Š åŠ è½½æ•°æ®é›†...")
    # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…ä½¿ç”¨æ—¶éœ€è¦æ ¹æ®ä½ çš„æ•°æ®åŠ è½½é€»è¾‘è°ƒæ•´
    # ä¸ºäº†æ¼”ç¤ºï¼Œå‡è®¾ä½¿ç”¨test_loader

    # åŠ è½½ä¸¤ä¸ªæ¨¡å‹
    print("\n" + "=" * 80)
    print("1ï¸âƒ£ åŠ è½½æ— ä¸­æœŸèåˆæ¨¡å‹")
    print("=" * 80)
    model_without, config_without = load_model(args.checkpoint_without_fusion, args.device)

    print("\n" + "=" * 80)
    print("2ï¸âƒ£ åŠ è½½æœ‰ä¸­æœŸèåˆæ¨¡å‹")
    print("=" * 80)
    model_with, config_with = load_model(args.checkpoint_with_fusion, args.device)

    # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦æ ¹æ®ä½ çš„å®é™…æ•°æ®åŠ è½½æ–¹å¼è°ƒæ•´
    # å»ºè®®æä¾›ä¸€ä¸ªç®€å•çš„dataloader
    print("\nâš ï¸  æ³¨æ„ï¼šè¯·ç¡®ä¿æä¾›äº†æœ‰æ•ˆçš„æ•°æ®åŠ è½½å™¨")
    print("ç¤ºä¾‹ä»£ç éœ€è¦æ ¹æ®ä½ çš„å®é™…æ•°æ®æ ¼å¼è¿›è¡Œè°ƒæ•´")

    # TODO: å®é™…ä½¿ç”¨æ—¶ï¼Œåœ¨è¿™é‡ŒåŠ è½½ä½ çš„test_loader
    # test_loader = ...

    print("\nâœ… åˆ†æå®Œæˆï¼ç»“æœä¿å­˜åœ¨:", output_dir)


if __name__ == '__main__':
    main()
