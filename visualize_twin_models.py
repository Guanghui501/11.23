#!/usr/bin/env python
"""
åŒæ¨¡å‹ç‰¹å¾å¯è§†åŒ–è„šæœ¬
ç”¨äºç”Ÿæˆè®ºæ–‡çº§åˆ«çš„å¯¹æ¯”å›¾è¡¨
"""

import os
import argparse
import torch
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA
from sklearn.metrics.pairwise import cosine_similarity
from scipy.stats import pearsonr, spearmanr
import pandas as pd

# è®¾ç½®ç»˜å›¾é£æ ¼
sns.set_style("whitegrid")
plt.rcParams['font.size'] = 12
plt.rcParams['figure.dpi'] = 300

# å¯¼å…¥æ¨¡å‹
import sys
sys.path.insert(0, os.path.dirname(__file__))
from models.alignn import ALIGNN
from train_with_cross_modal_attention import load_dataset, get_dataset_paths
from data import get_train_val_loaders


def load_model(path, device):
    """åŠ è½½æ¨¡å‹"""
    print(f"ğŸ“¦ åŠ è½½æ¨¡å‹: {path}")
    ckpt = torch.load(path, map_location=device, weights_only=False)
    config = ckpt.get('config') or ckpt.get('model_config')
    model = ALIGNN(config)
    model.load_state_dict(ckpt['model'])
    model.to(device)
    model.eval()
    return model


def extract_features(model, loader, device, max_samples=None, feature_stage='final'):
    """
    æå–ç‰¹å¾

    Args:
        feature_stage: ç‰¹å¾é˜¶æ®µé€‰æ‹©
            - 'base': graph_base (GCNåï¼Œæ‰€æœ‰æ³¨æ„åŠ›å‰)
            - 'middle': graph_middle (ä¸­æœŸèåˆå)
            - 'fine': graph_fine (ç»†ç²’åº¦æ³¨æ„åŠ›å)
            - 'final': graph_features (æœ€ç»ˆç‰¹å¾ï¼Œé»˜è®¤)
    """
    features = []
    targets = []
    sample_count = 0

    # ç‰¹å¾é”®æ˜ å°„
    stage_key_map = {
        'base': 'graph_base',
        'middle': 'graph_middle',
        'fine': 'graph_fine',
        'final': 'graph_features'
    }

    feature_key = stage_key_map.get(feature_stage, 'graph_features')
    print(f"   æå–é˜¶æ®µ: {feature_stage} (é”®: {feature_key})")

    with torch.no_grad():
        for batch in tqdm(loader, desc="æå–ç‰¹å¾"):
            if len(batch) == 3:
                g, text, y = batch
                lg = None
            elif len(batch) == 4:
                g, lg, text, y = batch
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„batchæ ¼å¼: {len(batch)}ä¸ªå…ƒç´ ")

            g = g.to(device)
            if lg is not None:
                lg = lg.to(device)

            # å¤„ç†text
            if isinstance(text, dict):
                text = {k: v.to(device) for k, v in text.items()}
            elif torch.is_tensor(text):
                text = text.to(device)

            inputs = (g, lg, text) if lg is not None else (g, text)
            out = model(inputs, return_intermediate_features=True)

            # æ ¹æ®æŒ‡å®šé˜¶æ®µæå–ç‰¹å¾
            feat = out.get(feature_key)

            # å¦‚æœæŒ‡å®šé˜¶æ®µä¸å­˜åœ¨ï¼Œå›é€€åˆ°å…¶ä»–é˜¶æ®µ
            if feat is None:
                print(f"âš ï¸  è­¦å‘Š: {feature_key} ä¸å­˜åœ¨ï¼Œå°è¯•å›é€€...")
                feat = out.get('graph_features', out.get('graph_final', out.get('graph_base')))

            features.append(feat.cpu().numpy())
            targets.append(y.cpu().numpy())

            sample_count += y.size(0)
            if max_samples and sample_count >= max_samples:
                break

    return np.vstack(features), np.concatenate(targets)


def centered_kernel_alignment(X, Y):
    """è®¡ç®— CKA ç›¸ä¼¼åº¦"""
    X = X - X.mean(axis=0)
    Y = Y - Y.mean(axis=0)
    K = X @ X.T
    L = Y @ Y.T
    hsic = np.sum(K * L)
    denom = np.sqrt(np.sum(K * K) * np.sum(L * L))
    return hsic / denom if denom > 0 else 0.0


def plot_tsne_comparison(feat_base, feat_sga, targets, save_dir, feature_stage='final'):
    """t-SNE å¯è§†åŒ–å¯¹æ¯”"""
    print("\nğŸ“Š ç”Ÿæˆ t-SNE å¯è§†åŒ–...")

    # è®¡ç®— t-SNE
    print("   è®¡ç®— Baseline t-SNE...")
    tsne_base = TSNE(n_components=2, random_state=42, perplexity=30).fit_transform(feat_base)

    print("   è®¡ç®— SGANet t-SNE...")
    tsne_sga = TSNE(n_components=2, random_state=42, perplexity=30).fit_transform(feat_sga)

    # åˆ›å»ºå›¾è¡¨
    fig, axes = plt.subplots(1, 2, figsize=(16, 6))

    # ç»Ÿä¸€é¢œè‰²èŒƒå›´
    vmin, vmax = targets.min(), targets.max()

    # æ ‡é¢˜åç¼€
    stage_suffix = f" [{feature_stage.upper()} stage]"

    # Baseline
    scatter1 = axes[0].scatter(tsne_base[:, 0], tsne_base[:, 1],
                               c=targets, cmap='viridis', alpha=0.6, s=20,
                               vmin=vmin, vmax=vmax)
    axes[0].set_title('Baseline Model' + stage_suffix, fontsize=14, fontweight='bold')
    axes[0].set_xlabel('t-SNE Dimension 1', fontsize=12)
    axes[0].set_ylabel('t-SNE Dimension 2', fontsize=12)
    axes[0].grid(True, alpha=0.3)

    # SGANet
    scatter2 = axes[1].scatter(tsne_sga[:, 0], tsne_sga[:, 1],
                               c=targets, cmap='viridis', alpha=0.6, s=20,
                               vmin=vmin, vmax=vmax)
    axes[1].set_title('SGANet (With Middle Fusion)' + stage_suffix, fontsize=14, fontweight='bold')
    axes[1].set_xlabel('t-SNE Dimension 1', fontsize=12)
    axes[1].set_ylabel('t-SNE Dimension 2', fontsize=12)
    axes[1].grid(True, alpha=0.3)

    # æ·»åŠ é¢œè‰²æ¡
    cbar = plt.colorbar(scatter2, ax=axes, fraction=0.046, pad=0.04)
    cbar.set_label('Target Value', fontsize=12)

    plt.tight_layout()
    save_path = os.path.join(save_dir, 'tsne_comparison.png')
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"âœ… ä¿å­˜: {save_path}")
    plt.close()


def plot_pca_comparison(feat_base, feat_sga, targets, save_dir, feature_stage='final'):
    """PCA å¯è§†åŒ–å¯¹æ¯”"""
    print("\nğŸ“Š ç”Ÿæˆ PCA å¯è§†åŒ–...")

    # è®¡ç®— PCA
    pca_base = PCA(n_components=2).fit_transform(feat_base)
    pca_sga = PCA(n_components=2).fit_transform(feat_sga)

    # åˆ›å»ºå›¾è¡¨
    fig, axes = plt.subplots(1, 2, figsize=(16, 6))

    vmin, vmax = targets.min(), targets.max()

    # æ ‡é¢˜åç¼€
    stage_suffix = f" [{feature_stage.upper()}]"

    # Baseline
    scatter1 = axes[0].scatter(pca_base[:, 0], pca_base[:, 1],
                               c=targets, cmap='viridis', alpha=0.6, s=20,
                               vmin=vmin, vmax=vmax)
    axes[0].set_title('Baseline Model (PCA)' + stage_suffix, fontsize=14, fontweight='bold')
    axes[0].set_xlabel('PC 1', fontsize=12)
    axes[0].set_ylabel('PC 2', fontsize=12)
    axes[0].grid(True, alpha=0.3)

    # SGANet
    scatter2 = axes[1].scatter(pca_sga[:, 0], pca_sga[:, 1],
                               c=targets, cmap='viridis', alpha=0.6, s=20,
                               vmin=vmin, vmax=vmax)
    axes[1].set_title('SGANet (PCA)' + stage_suffix, fontsize=14, fontweight='bold')
    axes[1].set_xlabel('PC 1', fontsize=12)
    axes[1].set_ylabel('PC 2', fontsize=12)
    axes[1].grid(True, alpha=0.3)

    cbar = plt.colorbar(scatter2, ax=axes, fraction=0.046, pad=0.04)
    cbar.set_label('Target Value', fontsize=12)

    plt.tight_layout()
    save_path = os.path.join(save_dir, 'pca_comparison.png')
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"âœ… ä¿å­˜: {save_path}")
    plt.close()


def plot_correlation_heatmap(feat_base, feat_sga, targets, save_dir):
    """ç‰¹å¾-ç›®æ ‡ç›¸å…³æ€§çƒ­å›¾"""
    print("\nğŸ“Š ç”Ÿæˆç›¸å…³æ€§çƒ­å›¾...")

    # è®¡ç®—æ¯ä¸ªç»´åº¦ä¸ç›®æ ‡çš„ç›¸å…³æ€§
    n_dims = min(feat_base.shape[1], 50)  # æœ€å¤šæ˜¾ç¤º50ä¸ªç»´åº¦

    corr_base = np.array([pearsonr(feat_base[:, i], targets)[0] for i in range(n_dims)])
    corr_sga = np.array([pearsonr(feat_sga[:, i], targets)[0] for i in range(n_dims)])

    # åˆ›å»ºçƒ­å›¾æ•°æ®
    heatmap_data = np.vstack([corr_base, corr_sga])

    fig, ax = plt.subplots(figsize=(16, 4))
    sns.heatmap(heatmap_data, cmap='RdBu_r', center=0,
                yticklabels=['Baseline', 'SGANet'],
                xticklabels=[f'D{i}' for i in range(n_dims)],
                cbar_kws={'label': 'Pearson Correlation'},
                ax=ax, vmin=-1, vmax=1)
    ax.set_title('Feature-Target Correlation per Dimension', fontsize=14, fontweight='bold')
    ax.set_xlabel('Feature Dimension', fontsize=12)

    plt.tight_layout()
    save_path = os.path.join(save_dir, 'correlation_heatmap.png')
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"âœ… ä¿å­˜: {save_path}")
    plt.close()


def plot_metrics_comparison(feat_base, feat_sga, targets, cka_score, save_dir):
    """ç»¼åˆæŒ‡æ ‡å¯¹æ¯”å›¾"""
    print("\nğŸ“Š ç”Ÿæˆç»¼åˆæŒ‡æ ‡å¯¹æ¯”...")

    # è®¡ç®—å„ç§æŒ‡æ ‡
    def get_avg_corr(X, y):
        corrs = [abs(pearsonr(X[:, i], y)[0]) for i in range(X.shape[1])]
        return np.mean(corrs)

    def get_max_corr(X, y):
        corrs = [abs(pearsonr(X[:, i], y)[0]) for i in range(X.shape[1])]
        return np.max(corrs)

    metrics_base = {
        'Avg Pearson': get_avg_corr(feat_base, targets),
        'Max Pearson': get_max_corr(feat_base, targets),
        'Feature Variance': np.mean(np.var(feat_base, axis=0)),
        'Feature Norm': np.mean(np.linalg.norm(feat_base, axis=1))
    }

    metrics_sga = {
        'Avg Pearson': get_avg_corr(feat_sga, targets),
        'Max Pearson': get_max_corr(feat_sga, targets),
        'Feature Variance': np.mean(np.var(feat_sga, axis=0)),
        'Feature Norm': np.mean(np.linalg.norm(feat_sga, axis=1))
    }

    # åˆ›å»ºå¯¹æ¯”å›¾
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    axes = axes.flatten()

    metric_names = list(metrics_base.keys())

    for idx, metric in enumerate(metric_names):
        ax = axes[idx]

        values = [metrics_base[metric], metrics_sga[metric]]
        labels = ['Baseline', 'SGANet']
        colors = ['#3498db', '#e74c3c']

        bars = ax.bar(labels, values, color=colors, alpha=0.7)
        ax.set_ylabel(metric, fontsize=12)
        ax.set_title(metric, fontweight='bold', fontsize=13)
        ax.grid(axis='y', alpha=0.3)

        # æ ‡æ³¨æ•°å€¼å’Œæå‡ç™¾åˆ†æ¯”
        for i, (bar, val) in enumerate(zip(bars, values)):
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height,
                   f'{val:.4f}',
                   ha='center', va='bottom', fontsize=11)

        # è®¡ç®—æå‡
        improvement = (metrics_sga[metric] - metrics_base[metric]) / metrics_base[metric] * 100
        ax.text(0.5, 0.95, f'Improvement: {improvement:+.1f}%',
               transform=ax.transAxes, ha='center', va='top',
               fontsize=10, bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))

    plt.suptitle('Feature Quality Metrics Comparison', fontsize=16, fontweight='bold', y=1.02)
    plt.tight_layout()
    save_path = os.path.join(save_dir, 'metrics_comparison.png')
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"âœ… ä¿å­˜: {save_path}")
    plt.close()


def plot_feature_distribution(feat_base, feat_sga, save_dir):
    """ç‰¹å¾åˆ†å¸ƒå¯¹æ¯”"""
    print("\nğŸ“Š ç”Ÿæˆç‰¹å¾åˆ†å¸ƒå¯¹æ¯”...")

    fig, axes = plt.subplots(1, 2, figsize=(14, 5))

    # è®¡ç®—æ¯ä¸ªæ ·æœ¬çš„ç‰¹å¾èŒƒæ•°
    norm_base = np.linalg.norm(feat_base, axis=1)
    norm_sga = np.linalg.norm(feat_sga, axis=1)

    # Baseline åˆ†å¸ƒ
    axes[0].hist(norm_base, bins=50, alpha=0.7, color='#3498db', edgecolor='black')
    axes[0].axvline(norm_base.mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {norm_base.mean():.2f}')
    axes[0].set_xlabel('Feature Norm', fontsize=12)
    axes[0].set_ylabel('Frequency', fontsize=12)
    axes[0].set_title('Baseline Model - Feature Norm Distribution', fontsize=13, fontweight='bold')
    axes[0].legend()
    axes[0].grid(True, alpha=0.3)

    # SGANet åˆ†å¸ƒ
    axes[1].hist(norm_sga, bins=50, alpha=0.7, color='#e74c3c', edgecolor='black')
    axes[1].axvline(norm_sga.mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {norm_sga.mean():.2f}')
    axes[1].set_xlabel('Feature Norm', fontsize=12)
    axes[1].set_ylabel('Frequency', fontsize=12)
    axes[1].set_title('SGANet - Feature Norm Distribution', fontsize=13, fontweight='bold')
    axes[1].legend()
    axes[1].grid(True, alpha=0.3)

    plt.tight_layout()
    save_path = os.path.join(save_dir, 'feature_distribution.png')
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"âœ… ä¿å­˜: {save_path}")
    plt.close()


def create_summary_report(feat_base, feat_sga, targets, cka_score, save_dir, feature_stage='final'):
    """ç”Ÿæˆæ€»ç»“æŠ¥å‘Š"""
    print("\nğŸ“ ç”Ÿæˆæ€»ç»“æŠ¥å‘Š...")

    def get_stats(X, y):
        avg_pearson = np.mean([abs(pearsonr(X[:, i], y)[0]) for i in range(X.shape[1])])
        max_pearson = np.max([abs(pearsonr(X[:, i], y)[0]) for i in range(X.shape[1])])
        variance = np.mean(np.var(X, axis=0))
        norm = np.mean(np.linalg.norm(X, axis=1))
        return avg_pearson, max_pearson, variance, norm

    stats_base = get_stats(feat_base, targets)
    stats_sga = get_stats(feat_sga, targets)

    # é˜¶æ®µè¯´æ˜
    stage_explanations = {
        'base': 'GCNåï¼Œæ‰€æœ‰æ³¨æ„åŠ›å‰ (å·®å¼‚ä¸»è¦æ¥è‡ªä¸­æœŸèåˆ)',
        'middle': 'ä¸­æœŸèåˆåç«‹å³æå–',
        'fine': 'ç»†ç²’åº¦æ³¨æ„åŠ›å',
        'final': 'æ‰€æœ‰æ¨¡å—å¤„ç†åçš„æœ€ç»ˆç‰¹å¾'
    }

    report = f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘         Twin Model Feature Space Comparison Report           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Feature Extraction Stage: {feature_stage.upper()}
{stage_explanations.get(feature_stage, '')}


1. Feature Structure Similarity (CKA Score)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
   CKA Score: {cka_score:.4f}

   Interpretation:
   {'âœ“ Feature spaces are highly similar (>0.95)' if cka_score > 0.95 else 'âœ“ Moderate structural change (0.85-0.95)' if cka_score > 0.85 else '! Significant structural change (<0.85)'}
   â†’ Middle fusion provides {'conservative but effective' if cka_score > 0.95 else 'moderate' if cka_score > 0.85 else 'revolutionary'} improvement


2. Physical Property Correlation
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
   Metric              Baseline    SGANet      Improvement
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   Avg Pearson Corr    {stats_base[0]:.4f}      {stats_sga[0]:.4f}      {(stats_sga[0]-stats_base[0])/stats_base[0]*100:+.1f}%
   Max Pearson Corr    {stats_base[1]:.4f}      {stats_sga[1]:.4f}      {(stats_sga[1]-stats_base[1])/stats_base[1]*100:+.1f}%

   Interpretation:
   âœ“ Avg correlation improvement: {(stats_sga[0]-stats_base[0])/stats_base[0]*100:.1f}%
   â†’ Features are more predictive of physical properties


3. Feature Expressiveness
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
   Metric              Baseline    SGANet      Change
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   Feature Variance    {stats_base[2]:.4f}      {stats_sga[2]:.4f}      {(stats_sga[2]-stats_base[2])/stats_base[2]*100:+.1f}%
   Feature Norm        {stats_base[3]:.4f}      {stats_sga[3]:.4f}      {(stats_sga[3]-stats_base[3])/stats_base[3]*100:+.1f}%

   Interpretation:
   {'âœ“ No feature collapse detected (variance increased)' if stats_sga[2] > stats_base[2] else 'âš  Potential feature collapse (variance decreased)'}
   â†’ Feature expressiveness {'enhanced' if stats_sga[2] > stats_base[2] else 'reduced'}


4. Overall Assessment
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
   âœ“ Structural Stability:  {'Excellent' if cka_score > 0.95 else 'Good' if cka_score > 0.85 else 'Moderate'}
   âœ“ Predictive Quality:    {'Significantly Improved' if (stats_sga[0]-stats_base[0])/stats_base[0] > 0.1 else 'Moderately Improved' if (stats_sga[0]-stats_base[0])/stats_base[0] > 0.05 else 'Slightly Improved'}
   âœ“ Feature Richness:      {'Enhanced' if stats_sga[2] > stats_base[2] else 'Unchanged'}

   Recommendation:
   {'âœ“ Middle fusion module is effective and ready for publication!' if (stats_sga[0]-stats_base[0])/stats_base[0] > 0.1 and cka_score > 0.9 else 'â†’ Results show improvement but may need further tuning'}


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Generated by: visualize_twin_models.py
"""

    # ä¿å­˜æŠ¥å‘Š
    report_path = os.path.join(save_dir, 'comparison_report.txt')
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(report)

    print(report)
    print(f"âœ… æŠ¥å‘Šä¿å­˜è‡³: {report_path}")


def main():
    parser = argparse.ArgumentParser(description='åŒæ¨¡å‹ç‰¹å¾å¯è§†åŒ–å¯¹æ¯”')
    parser.add_argument('--ckpt_base', required=True, help='åŸºçº¿æ¨¡å‹checkpointè·¯å¾„')
    parser.add_argument('--ckpt_sga', required=True, help='SGANetæ¨¡å‹checkpointè·¯å¾„')
    parser.add_argument('--root_dir', default='/public/home/ghzhang/crysmmnet-main/dataset',
                       help='æ•°æ®é›†æ ¹ç›®å½•')
    parser.add_argument('--dataset', default='jarvis', help='æ•°æ®é›†åç§°')
    parser.add_argument('--property', default='mbj_bandgap', help='ç›®æ ‡å±æ€§')
    parser.add_argument('--max_samples', type=int, default=1000, help='æœ€å¤§æ ·æœ¬æ•°')
    parser.add_argument('--batch_size', type=int, default=64, help='æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--save_dir', default='./twin_model_visualization',
                       help='ç»“æœä¿å­˜ç›®å½•')
    parser.add_argument('--device', default='cuda', help='è®¡ç®—è®¾å¤‡')
    parser.add_argument('--feature_stage', type=str, default='final',
                       choices=['base', 'middle', 'fine', 'final'],
                       help='æå–ç‰¹å¾çš„é˜¶æ®µ: base=GCNå, middle=ä¸­æœŸèåˆå, fine=ç»†ç²’åº¦æ³¨æ„åŠ›å, final=æœ€ç»ˆç‰¹å¾(é»˜è®¤)')
    args = parser.parse_args()

    # åˆ›å»ºä¿å­˜ç›®å½•
    os.makedirs(args.save_dir, exist_ok=True)

    device = torch.device(args.device if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ–¥ï¸  ä½¿ç”¨è®¾å¤‡: {device}")

    # æ˜¾ç¤ºç‰¹å¾æå–é˜¶æ®µ
    stage_descriptions = {
        'base': 'GCNåï¼Œæ‰€æœ‰æ³¨æ„åŠ›å‰ (Baseline: ALIGNN+GCN | SGANet: ALIGNN+ä¸­æœŸèåˆ+GCN)',
        'middle': 'ä¸­æœŸèåˆåç«‹å³æå– (ä»…SGANetæœ‰æ•ˆ)',
        'fine': 'ç»†ç²’åº¦æ³¨æ„åŠ›å (åŸå­-æ–‡æœ¬tokenäº¤äº’å)',
        'final': 'æœ€ç»ˆç‰¹å¾ (æ‰€æœ‰æ¨¡å—å¤„ç†å)'
    }
    print(f"\nğŸ¯ ç‰¹å¾æå–é˜¶æ®µ: {args.feature_stage}")
    print(f"   è¯´æ˜: {stage_descriptions[args.feature_stage]}")
    if args.feature_stage == 'base':
        print(f"   â­ æ¨èç”¨äºè¯„ä¼°ä¸­æœŸèåˆçš„ç‹¬ç«‹è´¡çŒ®")

    # åŠ è½½æ•°æ®
    print(f"\nğŸ“‚ åŠ è½½æ•°æ®é›†: {args.dataset} - {args.property}")
    cif_dir, id_prop_file = get_dataset_paths(args.root_dir, args.dataset, args.property)
    dataset = load_dataset(cif_dir, id_prop_file, args.dataset, args.property)

    # é‡‡æ ·
    if args.max_samples and len(dataset) > args.max_samples:
        print(f"âš ï¸  é‡‡æ · {args.max_samples} ä¸ªæ ·æœ¬")
        import random
        random.seed(42)
        dataset = random.sample(dataset, args.max_samples)

    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    _, _, test_loader, _ = get_train_val_loaders(
        dataset='user_data',
        dataset_array=dataset,
        target='target',
        batch_size=args.batch_size,
        atom_features='cgcnn',
        neighbor_strategy='k-nearest',
        line_graph=True,
        workers=0,
        pin_memory=False,
        n_train=10,
        n_val=10,
        n_test=len(dataset)-20,
        split_seed=42,
        save_dataloader=False,
        filename='temp_viz',
        id_tag='jid',
        use_canonize=True,
        cutoff=8.0,
        max_neighbors=12,
        output_dir=args.save_dir
    )

    # åŠ è½½æ¨¡å‹å¹¶æå–ç‰¹å¾
    print(f"\nğŸ“¦ æå–åŸºçº¿æ¨¡å‹ç‰¹å¾:")
    model_base = load_model(args.ckpt_base, device)
    feat_base, targets = extract_features(model_base, test_loader, device, args.max_samples, args.feature_stage)

    print(f"\nğŸ“¦ æå–SGANetæ¨¡å‹ç‰¹å¾:")
    model_sga = load_model(args.ckpt_sga, device)
    feat_sga, _ = extract_features(model_sga, test_loader, device, args.max_samples, args.feature_stage)

    print(f"\nâœ… ç‰¹å¾æå–å®Œæˆ:")
    print(f"   Baseline: {feat_base.shape}")
    print(f"   SGANet:   {feat_sga.shape}")
    print(f"   Targets:  {targets.shape}")

    # è®¡ç®— CKA
    print("\nğŸ” è®¡ç®—ç‰¹å¾ç›¸ä¼¼åº¦...")
    cka_score = centered_kernel_alignment(feat_base, feat_sga)
    print(f"   CKA Score: {cka_score:.4f}")

    # ç”Ÿæˆæ‰€æœ‰å¯è§†åŒ–
    print("\n" + "="*60)
    print("å¼€å§‹ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
    print("="*60)

    plot_tsne_comparison(feat_base, feat_sga, targets, args.save_dir, args.feature_stage)
    plot_pca_comparison(feat_base, feat_sga, targets, args.save_dir, args.feature_stage)
    plot_correlation_heatmap(feat_base, feat_sga, targets, args.save_dir)
    plot_metrics_comparison(feat_base, feat_sga, targets, cka_score, args.save_dir)
    plot_feature_distribution(feat_base, feat_sga, args.save_dir)
    create_summary_report(feat_base, feat_sga, targets, cka_score, args.save_dir, args.feature_stage)

    print("\n" + "="*60)
    print(f"ğŸ‰ æ‰€æœ‰å¯è§†åŒ–å®Œæˆ! ç»“æœä¿å­˜åœ¨: {args.save_dir}")
    print("="*60)
    print("\nç”Ÿæˆçš„æ–‡ä»¶:")
    print("  1. tsne_comparison.png          - t-SNE é™ç»´å¯¹æ¯”")
    print("  2. pca_comparison.png           - PCA é™ç»´å¯¹æ¯”")
    print("  3. correlation_heatmap.png      - ç‰¹å¾-ç›®æ ‡ç›¸å…³æ€§çƒ­å›¾")
    print("  4. metrics_comparison.png       - ç»¼åˆæŒ‡æ ‡å¯¹æ¯”")
    print("  5. feature_distribution.png     - ç‰¹å¾åˆ†å¸ƒå¯¹æ¯”")
    print("  6. comparison_report.txt        - è¯¦ç»†æ–‡æœ¬æŠ¥å‘Š")
    print("")


if __name__ == "__main__":
    main()
