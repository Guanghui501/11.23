#!/usr/bin/env python
"""
æµ‹è¯•å›¾ç‰¹å¾å•ç‹¬é¢„æµ‹åŠŸèƒ½
éªŒè¯æ¨¡å‹æ¶æ„å’Œå‰å‘ä¼ æ’­æ˜¯å¦æ­£å¸¸
"""

import torch
import dgl
from models.alignn import ALIGNN, ALIGNNConfig

def create_dummy_graph(num_nodes=10, num_edges=20):
    """åˆ›å»ºè™šæ‹Ÿå›¾ç”¨äºæµ‹è¯•"""
    src = torch.randint(0, num_nodes, (num_edges,))
    dst = torch.randint(0, num_nodes, (num_edges,))
    g = dgl.graph((src, dst))

    # èŠ‚ç‚¹ç‰¹å¾ (åŸå­ç‰¹å¾)
    g.ndata['atom_features'] = torch.randn(num_nodes, 92)

    # è¾¹ç‰¹å¾ (è·ç¦»)
    g.edata['r'] = torch.rand(num_edges) * 5.0 + 1.0

    return g

def create_dummy_line_graph(g):
    """åˆ›å»ºè™šæ‹Ÿçº¿å›¾"""
    lg = dgl.line_graph(g, backtracking=False)

    # è¾¹çš„è¾¹ç‰¹å¾ (é”®è§’ä½™å¼¦)
    num_lg_edges = lg.num_edges()
    lg.edata['h'] = torch.randn(num_lg_edges, 1)

    return lg

def create_dummy_text():
    """åˆ›å»ºè™šæ‹Ÿæ–‡æœ¬è¾“å…¥"""
    return ["This is a test crystal structure with high stability"]

def test_graph_only_prediction():
    """æµ‹è¯•å›¾ç‰¹å¾å•ç‹¬é¢„æµ‹æ¨¡å¼"""

    print("="*60)
    print("  æµ‹è¯•å›¾ç‰¹å¾å•ç‹¬é¢„æµ‹åŠŸèƒ½")
    print("="*60)
    print()

    # æµ‹è¯•1: use_only_graph_for_prediction = False (æ ‡å‡†æ¨¡å¼)
    print("ğŸ“Š æµ‹è¯•1: æ ‡å‡†èåˆæ¨¡å¼")
    print("-"*60)

    config1 = ALIGNNConfig(
        name="alignn",
        alignn_layers=2,
        gcn_layers=2,
        hidden_features=128,
        use_fine_grained_attention=True,
        fine_grained_hidden_dim=128,
        fine_grained_num_heads=4,
        use_cross_modal_attention=True,
        cross_modal_hidden_dim=128,
        cross_modal_num_heads=2,
        use_only_graph_for_prediction=False,  # æ ‡å‡†æ¨¡å¼
        output_features=1
    )

    model1 = ALIGNN(config1)
    print(f"âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ")
    print(f"   - use_only_graph_for_prediction: {model1.use_only_graph_for_prediction}")
    print(f"   - FC1å±‚è¾“å…¥ç»´åº¦: {model1.fc1.in_features}")
    print(f"   - FC1å±‚è¾“å‡ºç»´åº¦: {model1.fc1.out_features}")

    # åˆ›å»ºæµ‹è¯•æ•°æ®
    g = create_dummy_graph(num_nodes=10, num_edges=20)
    lg = create_dummy_line_graph(g)
    text = create_dummy_text()

    # æ‰¹å¤„ç†
    batch_g = dgl.batch([g])
    batch_lg = dgl.batch([lg])

    # å‰å‘ä¼ æ’­
    model1.eval()
    with torch.no_grad():
        try:
            output = model1((batch_g, batch_lg, text), return_intermediate_features=True)
            print(f"âœ… å‰å‘ä¼ æ’­æˆåŠŸ")
            print(f"   - é¢„æµ‹å½¢çŠ¶: {output['predictions'].shape}")
            print(f"   - é¢„æµ‹å€¼: {output['predictions'].item():.4f}")
            print(f"   - å›¾ç‰¹å¾å½¢çŠ¶: {output['graph_features'].shape}")
            print(f"   - æ–‡æœ¬ç‰¹å¾å½¢çŠ¶: {output['text_features'].shape}")
        except Exception as e:
            print(f"âŒ å‰å‘ä¼ æ’­å¤±è´¥: {e}")
            return False

    print()

    # æµ‹è¯•2: use_only_graph_for_prediction = True (å›¾ç‰¹å¾å•ç‹¬é¢„æµ‹)
    print("ğŸ“Š æµ‹è¯•2: å›¾ç‰¹å¾å•ç‹¬é¢„æµ‹æ¨¡å¼")
    print("-"*60)

    config2 = ALIGNNConfig(
        name="alignn",
        alignn_layers=2,
        gcn_layers=2,
        hidden_features=128,
        use_fine_grained_attention=True,
        fine_grained_hidden_dim=128,
        fine_grained_num_heads=4,
        use_cross_modal_attention=True,
        cross_modal_hidden_dim=128,
        cross_modal_num_heads=2,
        use_only_graph_for_prediction=True,  # å›¾ç‰¹å¾å•ç‹¬é¢„æµ‹
        output_features=1
    )

    model2 = ALIGNN(config2)
    print(f"âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ")
    print(f"   - use_only_graph_for_prediction: {model2.use_only_graph_for_prediction}")
    print(f"   - FC1å±‚è¾“å…¥ç»´åº¦: {model2.fc1.in_features}")
    print(f"   - FC1å±‚è¾“å‡ºç»´åº¦: {model2.fc1.out_features}")

    # å‰å‘ä¼ æ’­
    model2.eval()
    with torch.no_grad():
        try:
            output = model2((batch_g, batch_lg, text), return_intermediate_features=True)
            print(f"âœ… å‰å‘ä¼ æ’­æˆåŠŸ")
            print(f"   - é¢„æµ‹å½¢çŠ¶: {output['predictions'].shape}")
            print(f"   - é¢„æµ‹å€¼: {output['predictions'].item():.4f}")
            print(f"   - å›¾ç‰¹å¾å½¢çŠ¶: {output['graph_features'].shape}")
            print(f"   - æ–‡æœ¬ç‰¹å¾å½¢çŠ¶: {output['text_features'].shape}")
        except Exception as e:
            print(f"âŒ å‰å‘ä¼ æ’­å¤±è´¥: {e}")
            return False

    print()

    # æµ‹è¯•3: å¯¹æ¯”ä¸¤ç§æ¨¡å¼
    print("ğŸ“Š æµ‹è¯•3: å¯¹æ¯”ä¸¤ç§æ¨¡å¼")
    print("-"*60)

    # å‚æ•°æ•°é‡å¯¹æ¯”
    params1 = sum(p.numel() for p in model1.parameters())
    params2 = sum(p.numel() for p in model2.parameters())

    print(f"å‚æ•°æ•°é‡:")
    print(f"   - æ ‡å‡†æ¨¡å¼: {params1:,}")
    print(f"   - å›¾ç‰¹å¾é¢„æµ‹: {params2:,}")
    print(f"   - å·®å¼‚: {abs(params1 - params2):,}")

    if params1 == params2:
        print(f"âœ… å‚æ•°æ•°é‡ç›¸åŒ (é¢„æœŸè¡Œä¸º)")
    else:
        print(f"âš ï¸  å‚æ•°æ•°é‡ä¸åŒ (å¯èƒ½æ˜¯é…ç½®å¯¼è‡´)")

    print()

    # æµ‹è¯•4: ä¸ä½¿ç”¨cross-modal attentionçš„æƒ…å†µ
    print("ğŸ“Š æµ‹è¯•4: æ— å…¨å±€æ³¨æ„åŠ› + å›¾ç‰¹å¾é¢„æµ‹")
    print("-"*60)

    config3 = ALIGNNConfig(
        name="alignn",
        alignn_layers=2,
        gcn_layers=2,
        hidden_features=128,
        use_fine_grained_attention=True,
        fine_grained_hidden_dim=128,
        fine_grained_num_heads=4,
        use_cross_modal_attention=False,  # ä¸ä½¿ç”¨å…¨å±€æ³¨æ„åŠ›
        use_only_graph_for_prediction=True,
        output_features=1
    )

    model3 = ALIGNN(config3)
    print(f"âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ")
    print(f"   - use_cross_modal_attention: {model3.use_cross_modal_attention}")
    print(f"   - use_only_graph_for_prediction: {model3.use_only_graph_for_prediction}")
    print(f"   - FC1å±‚è¾“å…¥ç»´åº¦: {model3.fc1.in_features}")

    model3.eval()
    with torch.no_grad():
        try:
            output = model3((batch_g, batch_lg, text))
            print(f"âœ… å‰å‘ä¼ æ’­æˆåŠŸ")
            print(f"   - é¢„æµ‹å½¢çŠ¶: {output.shape}")
            print(f"   - é¢„æµ‹å€¼: {output.item():.4f}")
        except Exception as e:
            print(f"âŒ å‰å‘ä¼ æ’­å¤±è´¥: {e}")
            return False

    print()

    # æµ‹è¯•5: æ‰¹é‡æ•°æ®æµ‹è¯•
    print("ğŸ“Š æµ‹è¯•5: æ‰¹é‡æ•°æ®æµ‹è¯• (batch_size=3)")
    print("-"*60)

    # åˆ›å»ºæ‰¹é‡æ•°æ®
    graphs = [create_dummy_graph(num_nodes=8+i*2, num_edges=15+i*5) for i in range(3)]
    line_graphs = [create_dummy_line_graph(g) for g in graphs]
    texts = [
        "Crystal structure A with high conductivity",
        "Material B showing excellent stability",
        "Compound C with unique magnetic properties"
    ]

    batch_g_multi = dgl.batch(graphs)
    batch_lg_multi = dgl.batch(line_graphs)

    model2.eval()
    with torch.no_grad():
        try:
            output = model2((batch_g_multi, batch_lg_multi, texts), return_intermediate_features=True)
            print(f"âœ… æ‰¹é‡å‰å‘ä¼ æ’­æˆåŠŸ")
            print(f"   - é¢„æµ‹å½¢çŠ¶: {output['predictions'].shape}")
            print(f"   - é¢„æµ‹å€¼: {output['predictions'].tolist()}")
            print(f"   - å›¾ç‰¹å¾å½¢çŠ¶: {output['graph_features'].shape}")
            print(f"   - æ–‡æœ¬ç‰¹å¾å½¢çŠ¶: {output['text_features'].shape}")
        except Exception as e:
            print(f"âŒ æ‰¹é‡å‰å‘ä¼ æ’­å¤±è´¥: {e}")
            return False

    print()
    print("="*60)
    print("  âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡!")
    print("="*60)
    print()
    print("ğŸ“ æ€»ç»“:")
    print("   1. âœ… å›¾ç‰¹å¾å•ç‹¬é¢„æµ‹æ¨¡å¼æ­£å¸¸å·¥ä½œ")
    print("   2. âœ… æ¨¡å‹æ¶æ„æ­£ç¡®åˆå§‹åŒ–")
    print("   3. âœ… å‰å‘ä¼ æ’­æ— é”™è¯¯")
    print("   4. âœ… æ‰¹é‡å¤„ç†æ­£å¸¸")
    print("   5. âœ… å…¼å®¹ä¸åŒé…ç½®ç»„åˆ")
    print()

    return True


if __name__ == "__main__":
    success = test_graph_only_prediction()
    exit(0 if success else 1)
