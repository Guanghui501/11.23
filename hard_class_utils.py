#!/usr/bin/env python
"""
éš¾åˆ†æ ·æœ¬å¯è§†åŒ–çš„å…±äº«å·¥å…·å‡½æ•°
é¿å…å¾ªç¯å¯¼å…¥
"""

import os
import numpy as np
import torch
from tqdm import tqdm
from jarvis.core.atoms import Atoms
from models.alignn import ALIGNN
from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score


# æ™¶ç³»å®šä¹‰
CRYSTAL_SYSTEMS = {
    'cubic': 'Cubic',
    'hexagonal': 'Hexagonal',
    'trigonal': 'Trigonal',
    'tetragonal': 'Tetragonal',
    'orthorhombic': 'Orthorhombic',
    'monoclinic': 'Monoclinic',
    'triclinic': 'Triclinic'
}

CRYSTAL_SYSTEM_COLORS = {
    'cubic': '#e74c3c',        # çº¢è‰²
    'tetragonal': '#f39c12',   # æ©™è‰²
    'hexagonal': '#3498db',    # è“è‰²
    'trigonal': '#27ae60',     # ç»¿è‰²
    'orthorhombic': '#9b59b6', # ç´«è‰²
    'monoclinic': '#16a085',   # é’è‰²
    'triclinic': '#d35400'     # æ·±æ©™è‰²
}


def load_model(checkpoint_path, device='cpu'):
    """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
    print(f"ğŸ“‚ åŠ è½½æ¨¡å‹: {checkpoint_path}")
    checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)

    model_config = checkpoint.get('config', None)
    if model_config is None:
        raise ValueError("Checkpointä¸­æœªæ‰¾åˆ°æ¨¡å‹é…ç½®")

    model = ALIGNN(model_config)
    model.load_state_dict(checkpoint['model'])
    model.eval()
    model.to(device)

    # æ‰“å°ä¸­æœŸèåˆé…ç½®
    use_middle = model_config.use_middle_fusion if hasattr(model_config, 'use_middle_fusion') else False
    layers = model_config.middle_fusion_layers if hasattr(model_config, 'middle_fusion_layers') else 'N/A'
    print(f"   ä¸­æœŸèåˆ: {use_middle}")
    if use_middle:
        print(f"   èåˆå±‚: {layers}")

    return model, model_config


def extract_crystal_system_from_text(text):
    """ä»æ–‡æœ¬æè¿°ä¸­æå–æ™¶ç³»å…³é”®è¯"""
    if not text:
        return None

    text_lower = text.lower()
    for crystal_name in ['cubic', 'hexagonal', 'trigonal', 'tetragonal',
                         'orthorhombic', 'monoclinic', 'triclinic']:
        if crystal_name in text_lower:
            return crystal_name
    return None


def extract_crystal_systems_from_dataset(dataset_array, cif_dir):
    """
    ä»dataset_arrayä¸­æå–æ™¶ç³»ä¿¡æ¯
    ä¼˜å…ˆä»CIFæ–‡ä»¶æå–ï¼Œå¤±è´¥åˆ™ä»æ–‡æœ¬æè¿°ä¸­æå–
    """
    crystal_systems = []
    sample_ids = []
    cif_success = 0
    text_success = 0

    print("ğŸ”„ ä»CIFæ–‡ä»¶å’Œæ–‡æœ¬æè¿°ä¸­æå–æ™¶ç³»ä¿¡æ¯...")

    for idx, item in enumerate(tqdm(dataset_array, desc="è¯»å–æ™¶ç³»")):
        sample_id = item['jid']
        sample_ids.append(sample_id)
        crystal_system = None

        # æ–¹æ³•1: ä»CIFæ–‡ä»¶æå–
        try:
            cif_file = os.path.join(cif_dir, f"{sample_id}.cif")
            if os.path.exists(cif_file):
                atoms = Atoms.from_cif(cif_file)

                if hasattr(atoms.lattice, 'lattice_system'):
                    crystal_system = atoms.lattice.lattice_system
                elif hasattr(atoms.lattice, 'get_lattice_system'):
                    crystal_system = atoms.lattice.get_lattice_system()
                elif hasattr(atoms, 'get_spacegroup'):
                    sg = atoms.get_spacegroup()
                    if sg:
                        crystal_system = sg.crystal_system

                if crystal_system:
                    crystal_system = crystal_system.lower()
                    cif_success += 1
        except Exception as e:
            pass

        # æ–¹æ³•2: ä»æ–‡æœ¬æè¿°ä¸­æå–
        if not crystal_system and 'text' in item:
            crystal_system = extract_crystal_system_from_text(item['text'])
            if crystal_system:
                text_success += 1

        crystal_systems.append(crystal_system if crystal_system else 'unknown')

    print(f"\nâœ… æ™¶ç³»æå–å®Œæˆ:")
    print(f"   CIFæå–æˆåŠŸ: {cif_success}")
    print(f"   æ–‡æœ¬æå–æˆåŠŸ: {text_success}")
    print(f"   æå–å¤±è´¥(unknown): {len([cs for cs in crystal_systems if cs == 'unknown'])}")

    return crystal_systems, sample_ids


def filter_by_crystal_systems(dataset_array, crystal_systems, target_systems):
    """
    ç­›é€‰å‡ºåªåŒ…å«ç›®æ ‡æ™¶ç³»çš„æ ·æœ¬
    """
    print(f"\nğŸ” ç­›é€‰ç›®æ ‡æ™¶ç³»: {', '.join([CRYSTAL_SYSTEMS.get(cs, cs) for cs in target_systems])}")

    filtered_dataset = []
    filtered_systems = []
    filtered_indices = []

    for idx, (item, cs) in enumerate(zip(dataset_array, crystal_systems)):
        if cs in target_systems:
            filtered_dataset.append(item)
            filtered_systems.append(cs)
            filtered_indices.append(idx)

    print(f"âœ… ç­›é€‰å®Œæˆ:")
    print(f"   åŸå§‹æ ·æœ¬æ•°: {len(dataset_array)}")
    print(f"   ç­›é€‰åæ ·æœ¬æ•°: {len(filtered_dataset)}")

    # ç»Ÿè®¡å„æ™¶ç³»æ•°é‡
    for cs in target_systems:
        count = filtered_systems.count(cs)
        print(f"   {CRYSTAL_SYSTEMS.get(cs, cs)}: {count}")

    return filtered_dataset, filtered_systems, filtered_indices


def extract_features(model, data_loader, device='cpu'):
    """æå–ç‰¹å¾"""
    model.eval()
    features_list = []
    targets_list = []

    print("ğŸ”„ æå–ç‰¹å¾...")

    with torch.no_grad():
        for batch_idx, batch in enumerate(tqdm(data_loader, desc="å¤„ç†æ‰¹æ¬¡")):
            try:
                if len(batch) == 4:
                    g, lg, text, target = batch
                    model_input = (g.to(device), lg.to(device), text)
                else:
                    g, text, target = batch
                    model_input = (g.to(device), text)

                output = model(model_input, return_features=True)

                # æå–èåˆç‰¹å¾
                if isinstance(output, dict):
                    if 'fused_features' in output:
                        feat = output['fused_features']
                    elif 'graph_features' in output:
                        feat = output['graph_features']
                    else:
                        feat = output.get('features', None)
                        if feat is None:
                            print(f"âš ï¸  Batch {batch_idx}: æ— æ³•æå–ç‰¹å¾")
                            continue
                else:
                    feat = output

                features_list.append(feat.cpu().numpy())
                targets_list.append(target.cpu().numpy())

            except Exception as e:
                print(f"âš ï¸  å¤„ç†batch {batch_idx}æ—¶å‡ºé”™: {e}")
                continue

    features = np.vstack(features_list)
    targets = np.concatenate(targets_list)

    print(f"âœ… æå–å®Œæˆ: {features.shape}")
    return features, targets


def compute_clustering_metrics(features, labels):
    """è®¡ç®—èšç±»è´¨é‡æŒ‡æ ‡"""
    unique_labels = list(set(labels))
    label_to_int = {label: i for i, label in enumerate(unique_labels)}
    numeric_labels = np.array([label_to_int[label] for label in labels])

    if len(np.unique(numeric_labels)) < 2:
        return {'silhouette': np.nan, 'davies_bouldin': np.nan, 'calinski_harabasz': np.nan}

    metrics = {}
    try:
        metrics['silhouette'] = silhouette_score(features, numeric_labels)
    except:
        metrics['silhouette'] = np.nan

    try:
        metrics['davies_bouldin'] = davies_bouldin_score(features, numeric_labels)
    except:
        metrics['davies_bouldin'] = np.nan

    try:
        metrics['calinski_harabasz'] = calinski_harabasz_score(features, numeric_labels)
    except:
        metrics['calinski_harabasz'] = np.nan

    return metrics


def compute_class_separation(features, labels, class1, class2):
    """
    è®¡ç®—ä¸¤ä¸ªç±»åˆ«ä¹‹é—´çš„åˆ†ç¦»åº¦
    """
    mask1 = np.array(labels) == class1
    mask2 = np.array(labels) == class2

    feat1 = features[mask1]
    feat2 = features[mask2]

    # ç±»é—´è·ç¦» (è´¨å¿ƒä¹‹é—´çš„è·ç¦»)
    centroid1 = feat1.mean(axis=0)
    centroid2 = feat2.mean(axis=0)
    inter_class_dist = np.linalg.norm(centroid1 - centroid2)

    # ç±»å†…è·ç¦» (æ¯ä¸ªæ ·æœ¬åˆ°è‡ªå·±ç±»è´¨å¿ƒçš„å¹³å‡è·ç¦»)
    intra_class_dist_1 = np.mean([np.linalg.norm(f - centroid1) for f in feat1])
    intra_class_dist_2 = np.mean([np.linalg.norm(f - centroid2) for f in feat2])

    # åˆ†ç¦»æ¯”ç‡
    separation_ratio = inter_class_dist / (intra_class_dist_1 + intra_class_dist_2)

    return {
        'inter_class_dist': inter_class_dist,
        'intra_class_dist_1': intra_class_dist_1,
        'intra_class_dist_2': intra_class_dist_2,
        'separation_ratio': separation_ratio
    }
