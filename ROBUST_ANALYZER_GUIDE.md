# Robust Attention Analyzer ä½¿ç”¨æŒ‡å—

## ğŸ“– æ¦‚è¿°

å…¨æ–°çš„å¥å£®æ³¨æ„åŠ›åˆ†æç³»ç»Ÿï¼Œä¸“é—¨è®¾è®¡ç”¨äºå¤„ç†å„ç§è¾¹ç•Œæƒ…å†µï¼ŒåŒ…æ‹¬ï¼š
- âœ… æ‰€æœ‰åŸå­æ³¨æ„åŠ›ç›¸åŒçš„æƒ…å†µ
- âœ… å¤šå¤´æ³¨æ„åŠ›é€€åŒ–
- âœ… æ³¨æ„åŠ›åˆ†å¸ƒè¿‡äºé›†ä¸­
- âœ… ä»£ç ç‰ˆæœ¬ä¸åŒ¹é…
- âœ… è‡ªåŠ¨è¯Šæ–­å’Œé™çº§ç­–ç•¥

## ğŸš€ å¿«é€Ÿå¼€å§‹

### åŸºç¡€ç”¨æ³•

```bash
python demo_robust_attention.py \
    --model_path /path/to/checkpoint.pt \
    --cif_path /path/to/structure.cif \
    --text "Material description text..." \
    --save_dir ./results
```

### ç¤ºä¾‹

```bash
python demo_robust_attention.py \
    --model_path /public/home/ghzhang/models/best_model.pt \
    --cif_path /public/home/ghzhang/crysmmnet-main/dataset/jarvis/mbj_bandgap/cif/10.cif \
    --text "LiBa4Hf crystallizes cubic F-43m space group. structure consists clusters Ba4Hf framework." \
    --save_dir ./analysis_robust
```

## ğŸ” åŠŸèƒ½ç‰¹æ€§

### 1. è‡ªåŠ¨è´¨é‡è¯Šæ–­

ç³»ç»Ÿä¼šè‡ªåŠ¨è¯Šæ–­æ³¨æ„åŠ›æƒé‡è´¨é‡ï¼š

```
ğŸ”¬ æ³¨æ„åŠ›æƒé‡è´¨é‡è¯Šæ–­
================================================================================

1ï¸âƒ£ åŸºæœ¬ä¿¡æ¯:
   - Attention heads: 8
   - Atoms: 6
   - Sequence length: 79

2ï¸âƒ£ å¤šå¤´æ³¨æ„åŠ›åˆ†æ:
   - å¹³å‡å¤´é—´ç›¸å…³æ€§: 0.9998
   - å¤´å¤šæ ·æ€§åˆ†æ•°: 0.0002

3ï¸âƒ£ åŸå­ç‰¹å¼‚æ€§åˆ†æ:
   - å¹³å‡åŸå­é—´ç›¸å…³æ€§: 1.0000
   - åŸå­å¤šæ ·æ€§åˆ†æ•°: 0.0000

4ï¸âƒ£ æ³¨æ„åŠ›åˆ†å¸ƒåˆ†æ:
   - å¹³å‡ç†µ: 2.8456
   - æœ€å¤§å¯èƒ½ç†µ: 4.3694

5ï¸âƒ£ è¯Šæ–­ç»“è®º:
   - è´¨é‡è¯„ä¼°: POOR
   - å‘ç°é—®é¢˜:
      â€¢ æ‰€æœ‰attention headså‡ ä¹ç›¸åŒï¼ˆå¤šå¤´é€€åŒ–ï¼‰
      â€¢ æ‰€æœ‰åŸå­çš„æ³¨æ„åŠ›æ¨¡å¼å‡ ä¹ç›¸åŒ
   - å»ºè®®:
      â€¢ å»ºè®®ä½¿ç”¨å…¨å±€åˆ†æè€Œéé€åŸå­åˆ†æ
      â€¢ æ£€æŸ¥GNNå±‚è¾“å‡ºçš„èŠ‚ç‚¹ç‰¹å¾æ˜¯å¦è¿‡äºç›¸ä¼¼
      â€¢ è€ƒè™‘å‡å°‘GNNå±‚æ•°æˆ–æ·»åŠ æ®‹å·®è¿æ¥
```

### 2. è‡ªé€‚åº”åˆ†æç­–ç•¥

#### æƒ…å†µ A: åŸå­æ³¨æ„åŠ›æ­£å¸¸ï¼ˆä¸åŒï¼‰

ç³»ç»Ÿä½¿ç”¨**é€åŸå­åˆ†æ**ï¼š

```
âœ… åŸå­æ³¨æ„åŠ›æ¨¡å¼æ­£å¸¸ï¼Œä½¿ç”¨æ ‡å‡†åˆ†æ...

âš›ï¸  é€åŸå­æ³¨æ„åŠ›åˆ†æ
================================================================================

Ba_0:
  - ba(1)              0.125678
  - barium             0.089234
  - framework          0.076543
  - cluster            0.065432
  - cubic              0.054321

Ba_1:
  - coordinate         0.134567
  - 12-coordinate      0.098765
  - framework          0.087654
  ...
```

ç”Ÿæˆå¯è§†åŒ–ï¼š`per_atom_attention.png`

#### æƒ…å†µ B: åŸå­æ³¨æ„åŠ›ç›¸åŒ

ç³»ç»Ÿè‡ªåŠ¨åˆ‡æ¢åˆ°**å…¨å±€åˆ†æ**ï¼š

```
âš ï¸  æ£€æµ‹åˆ°åŸå­æ³¨æ„åŠ›æ¨¡å¼ç›¸åŒï¼Œä½¿ç”¨å…¨å±€åˆ†æç­–ç•¥...

ğŸ“Š å…¨å±€æ³¨æ„åŠ›æ¨¡å¼åˆ†æ
================================================================================

ğŸ”¤ å…¨å±€æœ€é‡è¦çš„ 15 ä¸ª Tokens:
Rank   Token                Importance   Category
------------------------------------------------------------
1      liba4hf              0.093750     Element
2      q6                   0.062500     Other
3      12-coordinate        0.041667     Crystallography
4      f-43m                0.031250     Crystallography
5      ba(1)                0.031250     Element
...
```

ç”Ÿæˆå¯è§†åŒ–ï¼š`global_attention_analysis.png`ï¼ˆåŒ…å«4ä¸ªå­å›¾ï¼‰

### 3. è¯¦ç»†ç»Ÿè®¡åˆ†æ

æ— è®ºä½¿ç”¨å“ªç§ç­–ç•¥ï¼Œéƒ½ä¼šæä¾›ç»Ÿè®¡ä¿¡æ¯ï¼š

```
ğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯:
   - æ³¨æ„åŠ›å¤´æ•°: 8
   - åŸå­æ•°: 6
   - åºåˆ—é•¿åº¦: 79
   - å¹³å‡æ³¨æ„åŠ›: 0.012658
   - æ³¨æ„åŠ›æ ‡å‡†å·®: 0.023456
   - ç¨€ç–åº¦: 45.67%
```

## ğŸ“Š è¾“å‡ºæ–‡ä»¶

### å…¨å±€åˆ†ææ¨¡å¼

`global_attention_analysis.png` åŒ…å«ï¼š
1. **Top 10 TokensæŸ±çŠ¶å›¾** - æœ€é‡è¦çš„tokensåŠå…¶æƒé‡
2. **Tokenç±»åˆ«åˆ†å¸ƒé¥¼å›¾** - Element/Crystallography/Chemistry/Other
3. **æœ€æ´»è·ƒHeadçš„çƒ­å›¾** - æ˜¾ç¤ºè¯¥headçš„atomÃ—tokenæ³¨æ„åŠ›æ¨¡å¼
4. **æ³¨æ„åŠ›æƒé‡åˆ†å¸ƒç›´æ–¹å›¾** - æƒé‡çš„ç»Ÿè®¡åˆ†å¸ƒ

### é€åŸå­åˆ†ææ¨¡å¼

`per_atom_attention.png` åŒ…å«ï¼š
- **çƒ­å›¾çŸ©é˜µ** - æ¯ä¸ªåŸå­çš„top-10 attended tokens

## ğŸ”§ ä½œä¸ºPythonæ¨¡å—ä½¿ç”¨

### æ–¹æ³• 1: ä½¿ç”¨ä¾¿æ·å‡½æ•°

```python
from robust_attention_analyzer import run_complete_analysis

results = run_complete_analysis(
    model=model,
    g=graph,
    lg=line_graph,
    text=description,
    atoms_object=atoms,
    save_dir='./output'
)

# è®¿é—®ç»“æœ
diagnosis = results['diagnosis']
statistics = results['statistics']

if diagnosis['use_alternative_analysis']:
    global_analysis = results['global_analysis']
    print(global_analysis['top_tokens'])
else:
    per_atom = results['per_atom_analysis']
    for atom_id, info in per_atom['atoms'].items():
        print(f"{atom_id}: {info['top_tokens']}")
```

### æ–¹æ³• 2: ç›´æ¥ä½¿ç”¨åˆ†æå™¨ç±»

```python
from robust_attention_analyzer import RobustAttentionAnalyzer

analyzer = RobustAttentionAnalyzer(model, device='cuda')

# 1. è¯Šæ–­è´¨é‡
diagnosis = analyzer.diagnose_attention_quality(
    attention_weights,
    elements,
    verbose=True
)

# 2. è‡ªé€‚åº”åˆ†æ
results = analyzer.analyze_with_fallback(
    attention_weights,
    atoms_object,
    text_tokens,
    save_dir='./output',
    top_k=15
)
```

## ğŸ’¡ ä½¿ç”¨å»ºè®®

### å¯¹äºè®­ç»ƒæ–°æ¨¡å‹

1. **å®šæœŸè¿è¡Œè¯Šæ–­**ï¼š
   ```bash
   # æ¯ä¸ªepochç»“æŸå
   python demo_robust_attention.py --model_path epoch_10.pt ...
   ```

2. **ç›‘æ§æŒ‡æ ‡**ï¼š
   - `atom_diversity` > 0.1ï¼ˆåŸå­æ³¨æ„åŠ›æœ‰å·®å¼‚ï¼‰
   - `head_diversity` > 0.1ï¼ˆå¤šå¤´æ³¨æ„åŠ›æœ‰å·®å¼‚ï¼‰
   - `entropy` > 2.0ï¼ˆæ³¨æ„åŠ›åˆ†å¸ƒä¸å¤ªé›†ä¸­ï¼‰

3. **æ ¹æ®è¯Šæ–­è°ƒæ•´**ï¼š
   - å¦‚æœ `atom_diversity` å¤ªä½ â†’ æ£€æŸ¥GNN over-smoothing
   - å¦‚æœ `head_diversity` å¤ªä½ â†’ æ·»åŠ head diversity loss
   - å¦‚æœ `entropy` å¤ªä½ â†’ æ£€æŸ¥temperature scaling

### å¯¹äºåˆ†æç°æœ‰æ¨¡å‹

1. **é¦–å…ˆè¿è¡Œè¯Šæ–­**ï¼š
   ```bash
   python demo_robust_attention.py ... --save_dir ./diagnosis
   ```

2. **æŸ¥çœ‹è´¨é‡è¯„ä¼°**ï¼š
   - `GOOD`: å¯ä»¥ä¿¡ä»»é€åŸå­åˆ†æ
   - `ACCEPTABLE`: è°¨æ…è§£è¯»
   - `POOR`: ä½¿ç”¨å…¨å±€åˆ†æï¼Œé—®é¢˜å¯èƒ½åœ¨æ¨¡å‹è®­ç»ƒ

3. **æ ¹æ®å»ºè®®æ”¹è¿›**ï¼š
   - æŒ‰ç…§è¯Šæ–­è¾“å‡ºçš„å»ºè®®è¿›è¡Œæ¨¡å‹è°ƒæ•´

## ğŸ†š ä¸åŸç³»ç»Ÿçš„åŒºåˆ«

| ç‰¹æ€§ | åŸç³»ç»Ÿ | Robust Analyzer |
|------|--------|----------------|
| å¤„ç†ç›¸åŒåŸå­æ³¨æ„åŠ› | âŒ æ˜¾ç¤ºé”™è¯¯ç»“æœ | âœ… è‡ªåŠ¨åˆ‡æ¢åˆ°å…¨å±€åˆ†æ |
| è´¨é‡è¯Šæ–­ | âŒ æ—  | âœ… 5ä¸ªç»´åº¦çš„è¯Šæ–­ |
| é™çº§ç­–ç•¥ | âŒ æ—  | âœ… è‡ªé€‚åº”é€‰æ‹©åˆ†ææ–¹æ³• |
| Tokenåˆ†ç±» | âš ï¸  ç®€å•è¿‡æ»¤ | âœ… æ™ºèƒ½åˆ†ç±»ï¼ˆElement/Crystallography/Chemistry/Otherï¼‰ |
| å¯è§†åŒ– | âš ï¸  å•ä¸€çƒ­å›¾ | âœ… å¤šå­å›¾ç»¼åˆåˆ†æ |
| ç»Ÿè®¡åˆ†æ | âŒ æ—  | âœ… å®Œæ•´ç»Ÿè®¡ä¿¡æ¯ |
| é”™è¯¯å¤„ç† | âš ï¸  å¯èƒ½å´©æºƒ | âœ… å¥å£®çš„å¼‚å¸¸å¤„ç† |

## ğŸ› æ•…éšœæ’é™¤

### é—®é¢˜ 1: æ¨¡å—å¯¼å…¥å¤±è´¥

```bash
ModuleNotFoundError: No module named 'robust_attention_analyzer'
```

**è§£å†³**ï¼š
```bash
# ç¡®ä¿åœ¨æ­£ç¡®ç›®å½•
cd /home/user/11.23

# æˆ–è€…æ·»åŠ åˆ° Python è·¯å¾„
export PYTHONPATH=/home/user/11.23:$PYTHONPATH
```

### é—®é¢˜ 2: æ‰€æœ‰åˆ†æéƒ½æ˜¾ç¤ºç›¸åŒ

**å¯èƒ½åŸå› **ï¼š
1. æ¨¡å‹ç¡®å®è¾“å‡ºç›¸åŒçš„æ³¨æ„åŠ›ï¼ˆè§è¯Šæ–­è¾“å‡ºï¼‰
2. ä»£ç ç‰ˆæœ¬ä¸åŒ¹é…ï¼ˆæ£€æŸ¥ Missing keys/Unexpected keysï¼‰

**è§£å†³**ï¼š
```bash
# æŸ¥çœ‹å®Œæ•´çš„æ¨¡å‹åŠ è½½æ—¥å¿—
python demo_robust_attention.py ... 2>&1 | grep -A5 "Missing keys\|Unexpected keys"
```

### é—®é¢˜ 3: å¯è§†åŒ–å›¾ç‰‡è´¨é‡å·®

**è§£å†³**ï¼š
ä¿®æ”¹ dpi å‚æ•°ï¼ˆé»˜è®¤300ï¼‰ï¼š

```python
# åœ¨ robust_attention_analyzer.py ä¸­æœç´¢ï¼š
plt.savefig(viz_path, dpi=300, bbox_inches='tight')

# æ”¹ä¸ºï¼š
plt.savefig(viz_path, dpi=600, bbox_inches='tight')  # æ›´é«˜åˆ†è¾¨ç‡
```

## ğŸ“š è¿›é˜¶ç”¨æ³•

### è‡ªå®šä¹‰åœç”¨è¯

```python
analyzer = RobustAttentionAnalyzer(model, device='cuda')

# æ·»åŠ è‡ªå®šä¹‰åœç”¨è¯
analyzer.stopwords.update({'custom', 'stopword', 'list'})

# æˆ–å®Œå…¨æ›¿æ¢
analyzer.stopwords = {'only', 'these', 'words'}
```

### è‡ªå®šä¹‰Tokenåˆ†ç±»

ä¿®æ”¹ `_categorize_token` æ–¹æ³•ï¼š

```python
def _categorize_token(self, token: str) -> str:
    # æ·»åŠ è‡ªå®šä¹‰ç±»åˆ«
    if 'band' in token.lower() or 'gap' in token.lower():
        return 'Electronic Property'

    # è°ƒç”¨åŸå§‹åˆ†ç±»
    return super()._categorize_token(token)
```

### æ‰¹é‡åˆ†æ

```python
import glob

for cif_file in glob.glob('/path/to/cif/*.cif'):
    cif_name = Path(cif_file).stem
    results = run_complete_analysis(
        model, g, lg, text, atoms,
        save_dir=f'./batch_analysis/{cif_name}'
    )
```

## ğŸ“ æ”¯æŒ

å¦‚æœ‰é—®é¢˜ï¼Œè¯·æŸ¥çœ‹ï¼š
1. `DIAGNOSTIC_GUIDE.md` - åŸæ³¨æ„åŠ›è¯Šæ–­æŒ‡å—
2. `ROOT_CAUSE_ANALYSIS.md` - æ ¹æœ¬åŸå› åˆ†æ
3. GitHub Issues

---

**æœ€åæ›´æ–°**: 2025-11-23
**ç‰ˆæœ¬**: 1.0.0
**å…¼å®¹æ€§**: PyTorch 1.x+, DGL 0.9+, JARVIS-Tools
