# Optuna è¶…å‚æ•°è°ƒä¼˜æŒ‡å—

æœ¬æŒ‡å—ä»‹ç»å¦‚ä½•ä½¿ç”¨ Optuna è¿›è¡Œ ALIGNN æ¨¡å‹çš„è¶…å‚æ•°è°ƒä¼˜ã€‚

## âœ¨ æ–°åŠŸèƒ½ï¼šä¸­æœŸèåˆå‚æ•°è°ƒä¼˜

ç°åœ¨æ”¯æŒä¼˜åŒ–**ä¸­æœŸèåˆï¼ˆMid-level Fusionï¼‰**å‚æ•°ï¼ä¸­æœŸèåˆåœ¨ ALIGNN å›¾ç¼–ç çš„ä¸­é—´å±‚æ’å…¥æ–‡æœ¬ä¿¡æ¯ï¼Œå…è®¸ï¼š
- åœ¨ä¸åŒå±‚çº§è¿›è¡Œå¤šæ¨¡æ€ç‰¹å¾èåˆ
- åŠ¨æ€é€‰æ‹©æœ€ä½³èåˆå±‚ä½ç½®ï¼ˆå¦‚ç¬¬2å±‚ã€ç¬¬1å’Œç¬¬3å±‚ç»„åˆç­‰ï¼‰
- ä¼˜åŒ–èåˆæœºåˆ¶çš„æ¶æ„å‚æ•°ï¼ˆéšè—ç»´åº¦ã€æ³¨æ„åŠ›å¤´æ•°ã€dropoutç­‰ï¼‰

æ€»è®¡å¯è°ƒè¶…å‚æ•°ï¼š**19+ ä¸ª**ï¼Œæ¶µç›–æ¨¡å‹æ¶æ„ã€è®­ç»ƒã€æ³¨æ„åŠ›æœºåˆ¶å’Œä¸­æœŸèåˆè®¾ç½®ã€‚

## ğŸ“‹ ç›®å½•

1. [å®‰è£…ä¾èµ–](#å®‰è£…ä¾èµ–)
2. [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
3. [è¯¦ç»†è¯´æ˜](#è¯¦ç»†è¯´æ˜)
4. [å¯è°ƒå‚æ•°](#å¯è°ƒå‚æ•°)
5. [ç¤ºä¾‹](#ç¤ºä¾‹)
6. [ç»“æœåˆ†æ](#ç»“æœåˆ†æ)

## ğŸ”§ å®‰è£…ä¾èµ–

```bash
pip install optuna plotly kaleido
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ­¥éª¤ 1: è¿è¡Œ Optuna è¶…å‚æ•°æœç´¢

```bash
# åŸºæœ¬ç”¨æ³•ï¼ˆ50 æ¬¡è¯•éªŒï¼‰
python train_optuna.py --n_trials 50 --output_dir optuna_results

# æ›´å¤šè¯•éªŒæ¬¡æ•°
python train_optuna.py --n_trials 100 --output_dir optuna_results

# å¹¶è¡Œè¿è¡Œï¼ˆä½¿ç”¨ 4 ä¸ªè¿›ç¨‹ï¼‰
python train_optuna.py --n_trials 100 --n_jobs 4 --output_dir optuna_results
```

### æ­¥éª¤ 2: ä½¿ç”¨æœ€ä½³å‚æ•°è®­ç»ƒå®Œæ•´æ¨¡å‹

```bash
python train_with_best_params.py \
    --best_params optuna_results/best_params.json \
    --epochs 500 \
    --output_dir best_model_output
```

## ğŸ“– è¯¦ç»†è¯´æ˜

### train_optuna.py

ä½¿ç”¨ Optuna è‡ªåŠ¨æœç´¢æœ€ä½³è¶…å‚æ•°çš„è„šæœ¬ã€‚

**å‚æ•°è¯´æ˜:**

```bash
--n_trials          # Optuna è¯•éªŒæ¬¡æ•°ï¼ˆé»˜è®¤: 50ï¼‰
--n_epochs          # æ¯æ¬¡è¯•éªŒçš„è®­ç»ƒè½®æ•°ï¼ˆé»˜è®¤: 100ï¼‰
--dataset           # æ•°æ®é›†åç§°ï¼ˆé»˜è®¤: user_dataï¼‰
--target            # ç›®æ ‡å±æ€§ï¼ˆé»˜è®¤: targetï¼‰
--output_dir        # è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤: optuna_resultsï¼‰
--study_name        # Optuna study åç§°ï¼ˆå¯é€‰ï¼‰
--n_jobs            # å¹¶è¡Œä½œä¸šæ•°ï¼ˆé»˜è®¤: 1ï¼Œ-1 è¡¨ç¤ºä½¿ç”¨æ‰€æœ‰ CPUï¼‰
--timeout           # ä¼˜åŒ–è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼Œå¯é€‰ï¼‰
--load_study        # åŠ è½½å·²æœ‰çš„ study æ•°æ®åº“è·¯å¾„ï¼ˆå¯é€‰ï¼‰
```

**è¾“å‡ºæ–‡ä»¶:**

- `best_params.json` - æœ€ä½³è¶…å‚æ•°
- `all_trials.csv` - æ‰€æœ‰è¯•éªŒçš„ç»“æœ
- `optuna_study.db` - Optuna study æ•°æ®åº“
- `optimization_history.html` - ä¼˜åŒ–å†å²å¯è§†åŒ–
- `param_importances.html` - å‚æ•°é‡è¦æ€§å¯è§†åŒ–
- `parallel_coordinate.html` - å¹¶è¡Œåæ ‡å›¾

### train_with_best_params.py

ä½¿ç”¨ Optuna æ‰¾åˆ°çš„æœ€ä½³å‚æ•°è®­ç»ƒå®Œæ•´æ¨¡å‹ã€‚

**å‚æ•°è¯´æ˜:**

```bash
--best_params               # æœ€ä½³å‚æ•° JSON æ–‡ä»¶è·¯å¾„ï¼ˆå¿…éœ€ï¼‰
--epochs                    # è®­ç»ƒè½®æ•°ï¼ˆé»˜è®¤: 500ï¼‰
--dataset                   # æ•°æ®é›†åç§°ï¼ˆé»˜è®¤: user_dataï¼‰
--target                    # ç›®æ ‡å±æ€§ï¼ˆé»˜è®¤: targetï¼‰
--output_dir                # è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤: best_model_outputï¼‰
--no_early_stopping         # ç¦ç”¨æ—©åœ
--early_stopping_patience   # æ—©åœè½®æ•°ï¼ˆé»˜è®¤: 50ï¼‰
```

**è¾“å‡ºæ–‡ä»¶:**

- `config.json` - è®­ç»ƒé…ç½®
- `training_history.json` - è®­ç»ƒå†å²
- `final_results.json` - æœ€ç»ˆç»“æœ
- `checkpoints/` - æ¨¡å‹æ£€æŸ¥ç‚¹
- `tb_logs/` - TensorBoard æ—¥å¿—

## ğŸ¯ å¯è°ƒå‚æ•°

### æ¨¡å‹æ¶æ„å‚æ•°

| å‚æ•° | æœç´¢èŒƒå›´ | è¯´æ˜ |
|------|---------|------|
| `alignn_layers` | [2, 6] | ALIGNN å±‚æ•° |
| `gcn_layers` | [2, 6] | GCN å±‚æ•° |
| `hidden_features` | {128, 256, 512} | éšè—å±‚ç‰¹å¾æ•° |
| `embedding_features` | {32, 64, 128} | åµŒå…¥ç‰¹å¾æ•° |
| `edge_input_features` | {40, 80, 120} | è¾¹è¾“å…¥ç‰¹å¾æ•° |
| `triplet_input_features` | {20, 40, 60} | ä¸‰å…ƒç»„è¾“å…¥ç‰¹å¾æ•° |

### è®­ç»ƒå‚æ•°

| å‚æ•° | æœç´¢èŒƒå›´ | è¯´æ˜ |
|------|---------|------|
| `learning_rate` | [1e-4, 1e-2] (log) | å­¦ä¹ ç‡ |
| `weight_decay` | [1e-6, 1e-3] (log) | æƒé‡è¡°å‡ |
| `batch_size` | {16, 32, 64, 128} | æ‰¹æ¬¡å¤§å° |
| `graph_dropout` | [0.0, 0.5] | å›¾dropoutç‡ |

### æ³¨æ„åŠ›æœºåˆ¶å‚æ•°

| å‚æ•° | æœç´¢èŒƒå›´ | è¯´æ˜ |
|------|---------|------|
| `use_cross_modal_attention` | {True, False} | æ˜¯å¦ä½¿ç”¨è·¨æ¨¡æ€æ³¨æ„åŠ› |
| `cross_modal_hidden_dim` | {128, 256, 512} | è·¨æ¨¡æ€æ³¨æ„åŠ›éšè—å±‚ç»´åº¦ |
| `cross_modal_num_heads` | {2, 4, 8} | è·¨æ¨¡æ€æ³¨æ„åŠ›å¤´æ•° |
| `cross_modal_dropout` | [0.0, 0.3] | è·¨æ¨¡æ€æ³¨æ„åŠ›dropout |
| `use_fine_grained_attention` | {True, False} | æ˜¯å¦ä½¿ç”¨ç»†ç²’åº¦æ³¨æ„åŠ› |
| `fine_grained_num_heads` | {4, 8, 16} | ç»†ç²’åº¦æ³¨æ„åŠ›å¤´æ•° |
| `fine_grained_dropout` | [0.0, 0.3] | ç»†ç²’åº¦æ³¨æ„åŠ›dropout |

### ä¸­æœŸèåˆå‚æ•°

| å‚æ•° | æœç´¢èŒƒå›´ | è¯´æ˜ |
|------|---------|------|
| `use_middle_fusion` | {True, False} | æ˜¯å¦ä½¿ç”¨ä¸­æœŸèåˆ |
| `middle_fusion_layers` | {"2", "1,3", "2,3", "1,2,3"} | æ’å…¥èåˆçš„å±‚ç´¢å¼•ï¼ˆæ ¹æ®æ¨¡å‹å±‚æ•°åŠ¨æ€è°ƒæ•´ï¼‰ |
| `middle_fusion_hidden_dim` | {64, 128, 256} | ä¸­æœŸèåˆéšè—å±‚ç»´åº¦ |
| `middle_fusion_num_heads` | {1, 2, 4} | ä¸­æœŸèåˆæ³¨æ„åŠ›å¤´æ•° |
| `middle_fusion_dropout` | [0.0, 0.3] | ä¸­æœŸèåˆdropout |

**æ³¨æ„**: ä¸­æœŸèåˆåœ¨ ALIGNN å±‚çš„ä¸­é—´ä½ç½®æ’å…¥æ–‡æœ¬-å›¾ç‰¹å¾èåˆï¼Œå…è®¸æ–‡æœ¬ä¿¡æ¯è°ƒåˆ¶èŠ‚ç‚¹è¡¨ç¤ºã€‚å±‚ç´¢å¼•çš„é€‰æ‹©ä¼šæ ¹æ® `alignn_layers` å‚æ•°è‡ªåŠ¨è°ƒæ•´ï¼š
- å¦‚æœ `alignn_layers >= 4`: å¯é€‰ "2", "1,3", "2,3", "1,2,3"
- å¦‚æœ `alignn_layers >= 3`: å¯é€‰ "1", "2", "1,2"
- å¦‚æœ `alignn_layers < 3`: å¯é€‰ "1"

## ğŸ’¡ ç¤ºä¾‹

### ç¤ºä¾‹ 1: åŸºæœ¬ä½¿ç”¨

```bash
# 1. è¿è¡Œ 50 æ¬¡è¯•éªŒ
python train_optuna.py --n_trials 50 --output_dir my_optuna_results

# 2. æŸ¥çœ‹æœ€ä½³å‚æ•°
cat my_optuna_results/best_params.json

# 3. ä½¿ç”¨æœ€ä½³å‚æ•°è®­ç»ƒ
python train_with_best_params.py \
    --best_params my_optuna_results/best_params.json \
    --epochs 500 \
    --output_dir my_best_model
```

### ç¤ºä¾‹ 2: è‡ªå®šä¹‰æ•°æ®é›†

```bash
# 1. å¯¹è‡ªå®šä¹‰æ•°æ®é›†è¿›è¡Œè°ƒä¼˜
python train_optuna.py \
    --n_trials 100 \
    --dataset user_data \
    --target band_gap \
    --output_dir bandgap_optuna

# 2. ä½¿ç”¨æœ€ä½³å‚æ•°è®­ç»ƒ
python train_with_best_params.py \
    --best_params bandgap_optuna/best_params.json \
    --dataset user_data \
    --target band_gap \
    --epochs 1000 \
    --output_dir bandgap_best_model
```

### ç¤ºä¾‹ 3: å¹¶è¡Œæœç´¢

```bash
# ä½¿ç”¨ 4 ä¸ªå¹¶è¡Œä½œä¸šåŠ é€Ÿæœç´¢
python train_optuna.py \
    --n_trials 200 \
    --n_jobs 4 \
    --output_dir parallel_optuna
```

### ç¤ºä¾‹ 4: ç»§ç»­ä¹‹å‰çš„æœç´¢

```bash
# åŠ è½½ä¹‹å‰çš„ study å¹¶ç»§ç»­æœç´¢
python train_optuna.py \
    --n_trials 50 \
    --load_study optuna_results/optuna_study.db \
    --study_name alignn_optuna_20240101_120000 \
    --output_dir optuna_results
```

### ç¤ºä¾‹ 5: è®¾ç½®è¶…æ—¶

```bash
# è®¾ç½® 6 å°æ—¶çš„è¶…æ—¶ï¼ˆ21600 ç§’ï¼‰
python train_optuna.py \
    --n_trials 1000 \
    --timeout 21600 \
    --output_dir optuna_timeout
```

## ğŸ“Š ç»“æœåˆ†æ

### æŸ¥çœ‹å¯è§†åŒ–ç»“æœ

è®­ç»ƒå®Œæˆåï¼Œåœ¨è¾“å‡ºç›®å½•ä¸­ä¼šç”Ÿæˆä»¥ä¸‹ HTML æ–‡ä»¶ï¼š

1. **optimization_history.html** - æ˜¾ç¤ºä¼˜åŒ–è¿‡ç¨‹ä¸­éªŒè¯ MAE çš„å˜åŒ–
2. **param_importances.html** - æ˜¾ç¤ºå„ä¸ªè¶…å‚æ•°çš„é‡è¦æ€§
3. **parallel_coordinate.html** - å¹¶è¡Œåæ ‡å›¾ï¼Œå±•ç¤ºå‚æ•°ç»„åˆ

åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€è¿™äº›æ–‡ä»¶ï¼š

```bash
# åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€
firefox optuna_results/optimization_history.html
firefox optuna_results/param_importances.html
firefox optuna_results/parallel_coordinate.html
```

### åˆ†ææ‰€æœ‰è¯•éªŒ

æ‰€æœ‰è¯•éªŒçš„è¯¦ç»†ç»“æœä¿å­˜åœ¨ CSV æ–‡ä»¶ä¸­ï¼š

```bash
# æŸ¥çœ‹æ‰€æœ‰è¯•éªŒ
cat optuna_results/all_trials.csv

# ä½¿ç”¨ pandas åˆ†æ
python -c "
import pandas as pd
df = pd.read_csv('optuna_results/all_trials.csv')
print(df.describe())
print('\næœ€ä½³ 10 ä¸ªè¯•éªŒ:')
print(df.nsmallest(10, 'value'))
"
```

### TensorBoard ç›‘æ§

ä½¿ç”¨æœ€ä½³å‚æ•°è®­ç»ƒæ—¶ï¼Œå¯ä»¥ç”¨ TensorBoard ç›‘æ§ï¼š

```bash
tensorboard --logdir best_model_output/tb_logs
```

## ğŸ” é«˜çº§æŠ€å·§

### è‡ªå®šä¹‰æœç´¢ç©ºé—´

å¦‚æœéœ€è¦è°ƒæ•´æœç´¢ç©ºé—´ï¼Œç¼–è¾‘ `train_optuna.py` ä¸­çš„ `objective` å‡½æ•°ï¼š

```python
# ç¤ºä¾‹ï¼šæ›´æ”¹å­¦ä¹ ç‡æœç´¢èŒƒå›´
learning_rate = trial.suggest_float("learning_rate", 1e-5, 1e-1, log=True)

# ç¤ºä¾‹ï¼šæ·»åŠ æ–°çš„ç¦»æ•£å‚æ•°
new_param = trial.suggest_categorical("new_param", [10, 20, 30])
```

### ä½¿ç”¨ä¸åŒçš„å‰ªæç­–ç•¥

åœ¨ `train_optuna.py` ä¸­ä¿®æ”¹ prunerï¼š

```python
# MedianPrunerï¼ˆé»˜è®¤ï¼‰
pruner = optuna.pruners.MedianPruner(
    n_startup_trials=5,
    n_warmup_steps=10,
    interval_steps=1,
)

# HyperbandPrunerï¼ˆæ›´æ¿€è¿›ï¼‰
pruner = optuna.pruners.HyperbandPruner(
    min_resource=1,
    max_resource=100,
    reduction_factor=3,
)

# SuccessiveHalvingPruner
pruner = optuna.pruners.SuccessiveHalvingPruner()
```

### å¤šç›®æ ‡ä¼˜åŒ–

å¦‚æœæƒ³åŒæ—¶ä¼˜åŒ–å¤šä¸ªæŒ‡æ ‡ï¼ˆå¦‚ MAE å’Œæ¨ç†é€Ÿåº¦ï¼‰ï¼Œå¯ä»¥ä¿®æ”¹ä¸ºå¤šç›®æ ‡ä¼˜åŒ–ï¼š

```python
study = optuna.create_study(
    directions=["minimize", "minimize"],  # [MAE, inference_time]
    pruner=pruner,
)
```

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **è®¡ç®—èµ„æº**: è¶…å‚æ•°æœç´¢éœ€è¦å¤§é‡è®¡ç®—èµ„æºï¼Œå»ºè®®ï¼š
   - å…ˆç”¨è¾ƒå°‘è¯•éªŒæ¬¡æ•°ï¼ˆå¦‚ 20-50ï¼‰å¿«é€Ÿæµ‹è¯•
   - ä½¿ç”¨ GPU åŠ é€Ÿè®­ç»ƒ
   - ä½¿ç”¨å¹¶è¡Œæœç´¢ï¼ˆ`--n_jobs`ï¼‰

2. **æ—©åœ**: åœ¨ Optuna æœç´¢æ—¶ä½¿ç”¨è¾ƒå°‘çš„ epochï¼ˆå¦‚ 100ï¼‰ï¼Œæœ€ç»ˆè®­ç»ƒæ—¶ä½¿ç”¨æ›´å¤š epochï¼ˆå¦‚ 500-1000ï¼‰

3. **å‰ªæ**: Optuna ä¼šè‡ªåŠ¨å‰ªæè¡¨ç°ä¸ä½³çš„è¯•éªŒï¼Œè¿™æ˜¯æ­£å¸¸çš„

4. **æ•°æ®é›†**: ç¡®ä¿æ•°æ®é›†å·²å‡†å¤‡å¥½å¹¶æ”¾åœ¨æ­£ç¡®ä½ç½®

5. **å†…å­˜**: å¦‚æœé‡åˆ°å†…å­˜ä¸è¶³ï¼Œå¯ä»¥ï¼š
   - å‡å° `batch_size`
   - å‡å° `hidden_features`
   - ä½¿ç”¨æ›´å°çš„æ¨¡å‹

## ğŸ“š å‚è€ƒèµ„æº

- [Optuna å®˜æ–¹æ–‡æ¡£](https://optuna.readthedocs.io/)
- [Optuna æ•™ç¨‹](https://optuna.readthedocs.io/en/stable/tutorial/index.html)
- [ALIGNN è®ºæ–‡](https://www.nature.com/articles/s41524-021-00650-1)

## ğŸ› æ•…éšœæ’é™¤

### é—®é¢˜ 1: CUDA out of memory

**è§£å†³æ–¹æ¡ˆ:**
- å‡å° batch_size
- å‡å°æ¨¡å‹å¤§å°ï¼ˆhidden_features, alignn_layersï¼‰
- ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯

### é—®é¢˜ 2: æ‰€æœ‰è¯•éªŒéƒ½è¢«å‰ªæ

**è§£å†³æ–¹æ¡ˆ:**
- å¢åŠ  `n_startup_trials`
- å¢åŠ  `n_warmup_steps`
- è°ƒæ•´å‰ªæç­–ç•¥

### é—®é¢˜ 3: æœç´¢æ—¶é—´è¿‡é•¿

**è§£å†³æ–¹æ¡ˆ:**
- å‡å°‘æ¯æ¬¡è¯•éªŒçš„ epoch æ•°ï¼ˆ`--n_epochs`ï¼‰
- ä½¿ç”¨å¹¶è¡Œæœç´¢ï¼ˆ`--n_jobs`ï¼‰
- è®¾ç½®è¶…æ—¶æ—¶é—´ï¼ˆ`--timeout`ï¼‰

### é—®é¢˜ 4: æ— æ³•ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨

**è§£å†³æ–¹æ¡ˆ:**
```bash
pip install plotly kaleido
```

---

**ç¥æ‚¨è°ƒå‚é¡ºåˆ©ï¼** ğŸ‰
