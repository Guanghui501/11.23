#!/usr/bin/env python
"""
éš¾åˆ†æ ·æœ¬å¯è§†åŒ– (Hard Class Subset)
èšç„¦äºæœ€å®¹æ˜“æ··æ·†çš„æ™¶ç³»å¯¹ï¼Œå±•ç¤ºæ¨¡å‹çš„åŒºåˆ†èƒ½åŠ›

ä¸“æ³¨äºå‡ ä½•ä¸Šæœ€ç›¸ä¼¼çš„æ™¶ç³»å¯¹ï¼š
- Cubic (ç«‹æ–¹) vs Tetragonal (å››æ–¹)
- å¯æ‰©å±•åˆ°å…¶ä»–å®¹æ˜“æ··æ·†çš„æ™¶ç³»å¯¹

ä½¿ç”¨æ–¹æ³•:
    python visualize_hard_class_subset.py \
        --checkpoint_without_fusion model_no_fusion.pth \
        --checkpoint_with_fusion model_with_fusion.pth \
        --data_dir /path/to/dataset \
        --class_pair cubic,tetragonal \
        --output_dir hard_class_results
"""

import os
import argparse
import numpy as np
import pandas as pd
import torch
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

# é™ç»´å’Œèšç±»åˆ†æ
from sklearn.manifold import TSNE
from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score
from scipy.spatial.distance import cdist

try:
    import umap
    UMAP_AVAILABLE = True
except ImportError:
    UMAP_AVAILABLE = False
    print("âš ï¸  UMAPæœªå®‰è£…ï¼Œå°†ä»…ä½¿ç”¨t-SNE")

# å¯¼å…¥æ•°æ®å’Œæ¨¡å‹
from jarvis.core.atoms import Atoms
from data import get_torch_dataset
from torch.utils.data import DataLoader
from models.alignn import ALIGNN
from config import TrainingConfig

# è®¾ç½®ç»˜å›¾é£æ ¼
sns.set_style("whitegrid")
plt.rcParams['font.size'] = 14
plt.rcParams['axes.labelsize'] = 16
plt.rcParams['axes.titlesize'] = 17
plt.rcParams['figure.titlesize'] = 19
plt.rcParams['legend.fontsize'] = 14
plt.rcParams['xtick.labelsize'] = 13
plt.rcParams['ytick.labelsize'] = 13


# æ™¶ç³»å®šä¹‰
CRYSTAL_SYSTEMS = {
    'cubic': 'Cubic',
    'hexagonal': 'Hexagonal',
    'trigonal': 'Trigonal',
    'tetragonal': 'Tetragonal',
    'orthorhombic': 'Orthorhombic',
    'monoclinic': 'Monoclinic',
    'triclinic': 'Triclinic'
}

CRYSTAL_SYSTEM_COLORS = {
    'cubic': '#e74c3c',        # çº¢è‰²
    'tetragonal': '#f39c12',   # æ©™è‰²
    'hexagonal': '#3498db',    # è“è‰²
    'trigonal': '#27ae60',     # ç»¿è‰²
    'orthorhombic': '#9b59b6', # ç´«è‰²
    'monoclinic': '#16a085',   # é’è‰²
    'triclinic': '#d35400'     # æ·±æ©™è‰²
}


def load_model(checkpoint_path, device='cpu'):
    """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
    print(f"ğŸ“‚ åŠ è½½æ¨¡å‹: {checkpoint_path}")
    checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)

    model_config = checkpoint.get('config', None)
    if model_config is None:
        raise ValueError("Checkpointä¸­æœªæ‰¾åˆ°æ¨¡å‹é…ç½®")

    model = ALIGNN(model_config)
    model.load_state_dict(checkpoint['model'])
    model.eval()
    model.to(device)

    # æ‰“å°ä¸­æœŸèåˆé…ç½®
    use_middle = model_config.use_middle_fusion if hasattr(model_config, 'use_middle_fusion') else False
    layers = model_config.middle_fusion_layers if hasattr(model_config, 'middle_fusion_layers') else 'N/A'
    print(f"   ä¸­æœŸèåˆ: {use_middle}")
    if use_middle:
        print(f"   èåˆå±‚: {layers}")

    return model, model_config


def extract_crystal_system_from_text(text):
    """ä»æ–‡æœ¬æè¿°ä¸­æå–æ™¶ç³»å…³é”®è¯"""
    if not text:
        return None

    text_lower = text.lower()
    for crystal_name in ['cubic', 'hexagonal', 'trigonal', 'tetragonal',
                         'orthorhombic', 'monoclinic', 'triclinic']:
        if crystal_name in text_lower:
            return crystal_name
    return None


def extract_crystal_systems_from_dataset(dataset_array, cif_dir):
    """
    ä»dataset_arrayä¸­æå–æ™¶ç³»ä¿¡æ¯
    ä¼˜å…ˆä»CIFæ–‡ä»¶æå–ï¼Œå¤±è´¥åˆ™ä»æ–‡æœ¬æè¿°ä¸­æå–
    """
    crystal_systems = []
    sample_ids = []
    cif_success = 0
    text_success = 0

    print("ğŸ”„ ä»CIFæ–‡ä»¶å’Œæ–‡æœ¬æè¿°ä¸­æå–æ™¶ç³»ä¿¡æ¯...")

    for idx, item in enumerate(tqdm(dataset_array, desc="è¯»å–æ™¶ç³»")):
        sample_id = item['jid']
        sample_ids.append(sample_id)
        crystal_system = None

        # æ–¹æ³•1: ä»CIFæ–‡ä»¶æå–
        try:
            cif_file = os.path.join(cif_dir, f"{sample_id}.cif")
            if os.path.exists(cif_file):
                atoms = Atoms.from_cif(cif_file)

                if hasattr(atoms.lattice, 'lattice_system'):
                    crystal_system = atoms.lattice.lattice_system
                elif hasattr(atoms.lattice, 'get_lattice_system'):
                    crystal_system = atoms.lattice.get_lattice_system()
                elif hasattr(atoms, 'get_spacegroup'):
                    sg = atoms.get_spacegroup()
                    if sg:
                        crystal_system = sg.crystal_system

                if crystal_system:
                    crystal_system = crystal_system.lower()
                    cif_success += 1
        except Exception as e:
            pass

        # æ–¹æ³•2: ä»æ–‡æœ¬æè¿°ä¸­æå–
        if not crystal_system and 'text' in item:
            crystal_system = extract_crystal_system_from_text(item['text'])
            if crystal_system:
                text_success += 1

        crystal_systems.append(crystal_system if crystal_system else 'unknown')

    print(f"\nâœ… æ™¶ç³»æå–å®Œæˆ:")
    print(f"   CIFæå–æˆåŠŸ: {cif_success}")
    print(f"   æ–‡æœ¬æå–æˆåŠŸ: {text_success}")
    print(f"   æå–å¤±è´¥(unknown): {len([cs for cs in crystal_systems if cs == 'unknown'])}")

    return crystal_systems, sample_ids


def filter_by_crystal_systems(dataset_array, crystal_systems, target_systems):
    """
    ç­›é€‰å‡ºåªåŒ…å«ç›®æ ‡æ™¶ç³»çš„æ ·æœ¬

    Args:
        dataset_array: åŸå§‹æ•°æ®é›†
        crystal_systems: æ™¶ç³»åˆ—è¡¨
        target_systems: ç›®æ ‡æ™¶ç³»åˆ—è¡¨ï¼Œå¦‚ ['cubic', 'tetragonal']

    Returns:
        filtered_dataset: è¿‡æ»¤åçš„æ•°æ®é›†
        filtered_systems: è¿‡æ»¤åçš„æ™¶ç³»åˆ—è¡¨
        filtered_indices: è¿‡æ»¤åçš„åŸå§‹ç´¢å¼•
    """
    print(f"\nğŸ” ç­›é€‰ç›®æ ‡æ™¶ç³»: {', '.join([CRYSTAL_SYSTEMS.get(cs, cs) for cs in target_systems])}")

    filtered_dataset = []
    filtered_systems = []
    filtered_indices = []

    for idx, (item, cs) in enumerate(zip(dataset_array, crystal_systems)):
        if cs in target_systems:
            filtered_dataset.append(item)
            filtered_systems.append(cs)
            filtered_indices.append(idx)

    print(f"âœ… ç­›é€‰å®Œæˆ:")
    print(f"   åŸå§‹æ ·æœ¬æ•°: {len(dataset_array)}")
    print(f"   ç­›é€‰åæ ·æœ¬æ•°: {len(filtered_dataset)}")

    # ç»Ÿè®¡å„æ™¶ç³»æ•°é‡
    for cs in target_systems:
        count = filtered_systems.count(cs)
        print(f"   {CRYSTAL_SYSTEMS.get(cs, cs)}: {count}")

    return filtered_dataset, filtered_systems, filtered_indices


def extract_features(model, data_loader, device='cpu'):
    """æå–ç‰¹å¾"""
    model.eval()
    features_list = []
    targets_list = []

    print("ğŸ”„ æå–ç‰¹å¾...")

    with torch.no_grad():
        for batch_idx, batch in enumerate(tqdm(data_loader, desc="å¤„ç†æ‰¹æ¬¡")):
            try:
                if len(batch) == 4:
                    g, lg, text, target = batch
                    model_input = (g.to(device), lg.to(device), text)
                else:
                    g, text, target = batch
                    model_input = (g.to(device), text)

                output = model(model_input, return_features=True)

                # æå–èåˆç‰¹å¾
                if isinstance(output, dict):
                    if 'fused_features' in output:
                        feat = output['fused_features']
                    elif 'graph_features' in output:
                        feat = output['graph_features']
                    else:
                        feat = output.get('features', None)
                        if feat is None:
                            print(f"âš ï¸  Batch {batch_idx}: æ— æ³•æå–ç‰¹å¾")
                            continue
                else:
                    feat = output

                features_list.append(feat.cpu().numpy())
                targets_list.append(target.cpu().numpy())

            except Exception as e:
                print(f"âš ï¸  å¤„ç†batch {batch_idx}æ—¶å‡ºé”™: {e}")
                continue

    features = np.vstack(features_list)
    targets = np.concatenate(targets_list)

    print(f"âœ… æå–å®Œæˆ: {features.shape}")
    return features, targets


def compute_clustering_metrics(features, labels):
    """è®¡ç®—èšç±»è´¨é‡æŒ‡æ ‡"""
    unique_labels = list(set(labels))
    label_to_int = {label: i for i, label in enumerate(unique_labels)}
    numeric_labels = np.array([label_to_int[label] for label in labels])

    if len(np.unique(numeric_labels)) < 2:
        return {'silhouette': np.nan, 'davies_bouldin': np.nan, 'calinski_harabasz': np.nan}

    metrics = {}
    try:
        metrics['silhouette'] = silhouette_score(features, numeric_labels)
    except:
        metrics['silhouette'] = np.nan

    try:
        metrics['davies_bouldin'] = davies_bouldin_score(features, numeric_labels)
    except:
        metrics['davies_bouldin'] = np.nan

    try:
        metrics['calinski_harabasz'] = calinski_harabasz_score(features, numeric_labels)
    except:
        metrics['calinski_harabasz'] = np.nan

    return metrics


def compute_class_separation(features, labels, class1, class2):
    """
    è®¡ç®—ä¸¤ä¸ªç±»åˆ«ä¹‹é—´çš„åˆ†ç¦»åº¦

    Returns:
        inter_class_dist: ç±»é—´è·ç¦»ï¼ˆå‡å€¼ä¹‹é—´çš„è·ç¦»ï¼‰
        intra_class_dist_1: ç±»1çš„ç±»å†…è·ç¦»ï¼ˆå¹³å‡è·ç¦»ï¼‰
        intra_class_dist_2: ç±»2çš„ç±»å†…è·ç¦»ï¼ˆå¹³å‡è·ç¦»ï¼‰
        separation_ratio: åˆ†ç¦»æ¯”ç‡ = inter_class_dist / (intra_class_dist_1 + intra_class_dist_2)
    """
    mask1 = np.array(labels) == class1
    mask2 = np.array(labels) == class2

    feat1 = features[mask1]
    feat2 = features[mask2]

    # ç±»é—´è·ç¦» (è´¨å¿ƒä¹‹é—´çš„è·ç¦»)
    centroid1 = feat1.mean(axis=0)
    centroid2 = feat2.mean(axis=0)
    inter_class_dist = np.linalg.norm(centroid1 - centroid2)

    # ç±»å†…è·ç¦» (æ¯ä¸ªæ ·æœ¬åˆ°è‡ªå·±ç±»è´¨å¿ƒçš„å¹³å‡è·ç¦»)
    intra_class_dist_1 = np.mean([np.linalg.norm(f - centroid1) for f in feat1])
    intra_class_dist_2 = np.mean([np.linalg.norm(f - centroid2) for f in feat2])

    # åˆ†ç¦»æ¯”ç‡
    separation_ratio = inter_class_dist / (intra_class_dist_1 + intra_class_dist_2)

    return {
        'inter_class_dist': inter_class_dist,
        'intra_class_dist_1': intra_class_dist_1,
        'intra_class_dist_2': intra_class_dist_2,
        'separation_ratio': separation_ratio
    }


def apply_reduction(features, method='tsne', n_components=2):
    """é™ç»´"""
    print(f"ğŸ”„ åº”ç”¨{method.upper()}é™ç»´...")

    if method == 'tsne':
        reducer = TSNE(
            n_components=n_components,
            perplexity=min(30, len(features) - 1),
            random_state=42,
            max_iter=1000
        )
    elif method == 'umap' and UMAP_AVAILABLE:
        reducer = umap.UMAP(
            n_components=n_components,
            n_neighbors=min(15, len(features) - 1),
            min_dist=0.1,
            random_state=42
        )
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„é™ç»´æ–¹æ³•: {method}")

    embedded = reducer.fit_transform(features)
    print(f"âœ… é™ç»´å®Œæˆ: {embedded.shape}")
    return embedded


def plot_hard_class_comparison(embedded_without, embedded_with, crystal_systems,
                                metrics_without, metrics_with,
                                sep_without, sep_with,
                                class_pair, output_path):
    """
    åˆ›å»ºéš¾åˆ†æ ·æœ¬å¯¹æ¯”å›¾
    """
    fig, axes = plt.subplots(1, 2, figsize=(20, 8))

    class1, class2 = class_pair

    for idx, (embedded, metrics, sep, title) in enumerate([
        (embedded_without, metrics_without, sep_without, 'Without Middle Fusion'),
        (embedded_with, metrics_with, sep_with, 'With Middle Fusion')
    ]):
        ax = axes[idx]

        # ç»˜åˆ¶ä¸¤ä¸ªç±»åˆ«
        for cs in [class1, class2]:
            mask = np.array(crystal_systems) == cs
            if mask.sum() == 0:
                continue

            ax.scatter(
                embedded[mask, 0],
                embedded[mask, 1],
                c=CRYSTAL_SYSTEM_COLORS.get(cs, 'gray'),
                label=f"{CRYSTAL_SYSTEMS.get(cs, cs)} (n={mask.sum()})",
                alpha=0.7,
                s=80,  # æ›´å¤§çš„ç‚¹
                edgecolors='white',
                linewidths=1.0
            )

        ax.set_xlabel('Dimension 1', fontsize=16)
        ax.set_ylabel('Dimension 2', fontsize=16)

        # å¢å¼ºçš„æ ‡é¢˜ï¼ŒåŒ…å«æ›´å¤šæŒ‡æ ‡
        title_text = f'{title}\n'
        title_text += f'Silhouette: {metrics["silhouette"]:.3f} | '
        title_text += f'Separation Ratio: {sep["separation_ratio"]:.3f}\n'
        title_text += f'Inter-class Dist: {sep["inter_class_dist"]:.2f} | '
        title_text += f'Intra-class Dist: {(sep["intra_class_dist_1"] + sep["intra_class_dist_2"])/2:.2f}'

        ax.set_title(title_text, fontsize=15, pad=15)
        ax.legend(loc='best', framealpha=0.95, fontsize=14, markerscale=1.5)
        ax.grid(True, alpha=0.3)

    class1_name = CRYSTAL_SYSTEMS.get(class1, class1)
    class2_name = CRYSTAL_SYSTEMS.get(class2, class2)
    plt.suptitle(f'Hard Class Subset Visualization: {class1_name} vs {class2_name}',
                 fontsize=19, y=0.98, weight='bold')
    plt.tight_layout()
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f"âœ… å›¾åƒå·²ä¿å­˜: {output_path}")
    plt.close()


def plot_separation_metrics(sep_without, sep_with, class_pair, output_path):
    """ç»˜åˆ¶ç±»åˆ†ç¦»åº¦æŒ‡æ ‡å¯¹æ¯”"""
    fig, axes = plt.subplots(1, 3, figsize=(18, 5))

    class1_name = CRYSTAL_SYSTEMS.get(class_pair[0], class_pair[0])
    class2_name = CRYSTAL_SYSTEMS.get(class_pair[1], class_pair[1])

    # 1. ç±»é—´è·ç¦»å¯¹æ¯”
    ax = axes[0]
    values = [sep_without['inter_class_dist'], sep_with['inter_class_dist']]
    bars = ax.bar(['Without Fusion', 'With Fusion'], values,
                 color=['#3498db', '#e74c3c'], alpha=0.75, edgecolor='black', linewidth=1.5)
    for bar in bars:
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2., height,
               f'{height:.2f}',
               ha='center', va='bottom', fontsize=12, fontweight='bold')
    ax.set_ylabel('Inter-class Distance', fontsize=14)
    ax.set_title('Inter-class Distance\n(Higher is Better)', fontsize=15, pad=12)
    ax.grid(True, axis='y', alpha=0.3)

    # 2. å¹³å‡ç±»å†…è·ç¦»å¯¹æ¯”
    ax = axes[1]
    intra_without = (sep_without['intra_class_dist_1'] + sep_without['intra_class_dist_2']) / 2
    intra_with = (sep_with['intra_class_dist_1'] + sep_with['intra_class_dist_2']) / 2
    values = [intra_without, intra_with]
    bars = ax.bar(['Without Fusion', 'With Fusion'], values,
                 color=['#3498db', '#e74c3c'], alpha=0.75, edgecolor='black', linewidth=1.5)
    for bar in bars:
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2., height,
               f'{height:.2f}',
               ha='center', va='bottom', fontsize=12, fontweight='bold')
    ax.set_ylabel('Average Intra-class Distance', fontsize=14)
    ax.set_title('Average Intra-class Distance\n(Lower is Better)', fontsize=15, pad=12)
    ax.grid(True, axis='y', alpha=0.3)

    # 3. åˆ†ç¦»æ¯”ç‡å¯¹æ¯”
    ax = axes[2]
    values = [sep_without['separation_ratio'], sep_with['separation_ratio']]
    bars = ax.bar(['Without Fusion', 'With Fusion'], values,
                 color=['#3498db', '#e74c3c'], alpha=0.75, edgecolor='black', linewidth=1.5)
    for bar in bars:
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2., height,
               f'{height:.3f}',
               ha='center', va='bottom', fontsize=12, fontweight='bold')
    ax.set_ylabel('Separation Ratio', fontsize=14)
    ax.set_title('Separation Ratio\n(Higher is Better)', fontsize=15, pad=12)
    ax.grid(True, axis='y', alpha=0.3)

    # å¦‚æœæœ‰æ”¹è¿›ï¼Œç»™èƒŒæ™¯åŠ ç»¿è‰²
    if sep_with['separation_ratio'] > sep_without['separation_ratio']:
        ax.set_facecolor('#eafaf1')

    plt.suptitle(f'Class Separation Metrics: {class1_name} vs {class2_name}',
                 fontsize=16, y=1.00, weight='bold')
    plt.tight_layout()
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f"âœ… åˆ†ç¦»åº¦æŒ‡æ ‡å›¾å·²ä¿å­˜: {output_path}")
    plt.close()


def main():
    parser = argparse.ArgumentParser(description='éš¾åˆ†æ ·æœ¬å¯è§†åŒ– (Hard Class Subset)')
    parser.add_argument('--checkpoint_without_fusion', type=str, required=True,
                       help='æ— ä¸­æœŸèåˆçš„æ¨¡å‹checkpoint')
    parser.add_argument('--checkpoint_with_fusion', type=str, required=True,
                       help='æœ‰ä¸­æœŸèåˆçš„æ¨¡å‹checkpoint')
    parser.add_argument('--data_dir', type=str, required=True,
                       help='æ•°æ®é›†ç›®å½•ï¼ˆåŒ…å«CIFæ–‡ä»¶ï¼‰')
    parser.add_argument('--dataset', type=str, default='jarvis',
                       help='æ•°æ®é›†ç±»å‹')
    parser.add_argument('--property', type=str, default='mbj_bandgap',
                       help='ç›®æ ‡å±æ€§')
    parser.add_argument('--class_pair', type=str, default='cubic,tetragonal',
                       help='è¦å¯¹æ¯”çš„æ™¶ç³»å¯¹ï¼Œç”¨é€—å·åˆ†éš”ï¼Œå¦‚ "cubic,tetragonal"')
    parser.add_argument('--n_samples', type=int, default=2000,
                       help='ä»æ•°æ®é›†ä¸­é‡‡æ ·çš„åˆå§‹æ ·æœ¬æ•°ï¼ˆåœ¨ç­›é€‰æ™¶ç³»ä¹‹å‰ï¼‰')
    parser.add_argument('--reduction_method', type=str, default='tsne',
                       choices=['tsne', 'umap'], help='é™ç»´æ–¹æ³•')
    parser.add_argument('--output_dir', type=str, default='hard_class_results',
                       help='è¾“å‡ºç›®å½•')
    parser.add_argument('--device', type=str, default='cuda' if torch.cuda.is_available() else 'cpu',
                       help='è®¾å¤‡')

    args = parser.parse_args()

    # è§£ææ™¶ç³»å¯¹
    class_pair = [cs.strip().lower() for cs in args.class_pair.split(',')]
    if len(class_pair) != 2:
        raise ValueError("--class_pair å¿…é¡»æŒ‡å®šä¸¤ä¸ªæ™¶ç³»ï¼Œç”¨é€—å·åˆ†éš”")

    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path(args.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    print("=" * 80)
    print("éš¾åˆ†æ ·æœ¬å¯è§†åŒ– (Hard Class Subset)")
    print("=" * 80)
    print(f"ç›®æ ‡æ™¶ç³»å¯¹: {CRYSTAL_SYSTEMS.get(class_pair[0], class_pair[0])} vs "
          f"{CRYSTAL_SYSTEMS.get(class_pair[1], class_pair[1])}")
    print("=" * 80)

    # æ„å»ºè·¯å¾„
    cif_dir = os.path.join(args.data_dir, f'{args.dataset}/{args.property}/cif/')
    id_prop_file = os.path.join(args.data_dir, f'{args.dataset}/{args.property}/description.csv')

    # åŠ è½½æ¨¡å‹
    print("\n" + "=" * 80)
    print("1ï¸âƒ£ åŠ è½½æ¨¡å‹")
    print("=" * 80)
    model_without, _ = load_model(args.checkpoint_without_fusion, args.device)
    model_with, _ = load_model(args.checkpoint_with_fusion, args.device)

    # åŠ è½½æ•°æ®
    print("\n" + "=" * 80)
    print("2ï¸âƒ£ åŠ è½½æ•°æ®é›†")
    print("=" * 80)

    import csv
    with open(id_prop_file, 'r') as f:
        reader = csv.reader(f)
        headings = next(reader)
        data = [row for row in reader]

    print(f"æ€»æ ·æœ¬æ•°: {len(data)}")

    # é‡‡æ ·
    if len(data) > args.n_samples:
        import random
        random.seed(42)
        data = random.sample(data, args.n_samples)
        print(f"éšæœºé‡‡æ · {args.n_samples} ä¸ªæ ·æœ¬")

    # æ„å»ºdataset_array
    dataset_array = []
    skipped = 0

    for j in tqdm(range(len(data)), desc="åŠ è½½æ ·æœ¬"):
        try:
            sample_id = data[j][0]
            target_val = float(data[j][2])
            description = data[j][3] if len(data[j]) > 3 else ""

            cif_file = os.path.join(cif_dir, f'{sample_id}.cif')
            if not os.path.exists(cif_file):
                skipped += 1
                continue

            atoms = Atoms.from_cif(cif_file)

            info = {
                "atoms": atoms.to_dict(),
                "jid": sample_id,
                "text": description if description else atoms.composition.reduced_formula,
                "target": target_val
            }

            dataset_array.append(info)

        except Exception as e:
            skipped += 1

    print(f"âœ“ æˆåŠŸåŠ è½½: {len(dataset_array)} æ ·æœ¬, è·³è¿‡: {skipped} æ ·æœ¬")

    # æå–æ™¶ç³»
    print("\n" + "=" * 80)
    print("3ï¸âƒ£ æå–æ™¶ç³»ä¿¡æ¯")
    print("=" * 80)
    crystal_systems, sample_ids = extract_crystal_systems_from_dataset(dataset_array, cif_dir)

    # ç­›é€‰ç›®æ ‡æ™¶ç³»
    print("\n" + "=" * 80)
    print("4ï¸âƒ£ ç­›é€‰ç›®æ ‡æ™¶ç³»")
    print("=" * 80)
    filtered_dataset, filtered_systems, filtered_indices = filter_by_crystal_systems(
        dataset_array, crystal_systems, class_pair
    )

    if len(filtered_dataset) < 10:
        print(f"âŒ é”™è¯¯: ç­›é€‰åçš„æ ·æœ¬æ•°å¤ªå°‘ ({len(filtered_dataset)})ï¼Œæ— æ³•è¿›è¡Œåˆ†æ")
        return

    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    print("\n" + "=" * 80)
    print("5ï¸âƒ£ åˆ›å»ºæ•°æ®åŠ è½½å™¨")
    print("=" * 80)

    test_data = get_torch_dataset(
        dataset=filtered_dataset,
        id_tag="jid",
        target="target",
        neighbor_strategy="k-nearest",
        atom_features="cgcnn",
        use_canonize=False,
        name=f"{args.dataset}_{args.property}_hard_class",
        line_graph=True,
        cutoff=8.0,
        max_neighbors=12,
    )

    test_loader = DataLoader(
        test_data,
        batch_size=32,
        shuffle=False,
        num_workers=0,
        pin_memory=False,
        collate_fn=test_data.collate_line_graph,
    )

    print(f"âœ“ æ•°æ®åŠ è½½å®Œæˆ: {len(test_data)} æ ·æœ¬")

    # æå–ç‰¹å¾
    print("\n" + "=" * 80)
    print("6ï¸âƒ£ æå–ç‰¹å¾")
    print("=" * 80)

    print("æ— ä¸­æœŸèåˆæ¨¡å‹:")
    features_without, targets = extract_features(model_without, test_loader, args.device)

    print("\næœ‰ä¸­æœŸèåˆæ¨¡å‹:")
    features_with, _ = extract_features(model_with, test_loader, args.device)

    # è®¡ç®—èšç±»æŒ‡æ ‡
    print("\n" + "=" * 80)
    print("7ï¸âƒ£ è®¡ç®—èšç±»æŒ‡æ ‡")
    print("=" * 80)

    metrics_without = compute_clustering_metrics(features_without, filtered_systems)
    metrics_with = compute_clustering_metrics(features_with, filtered_systems)

    print(f"\næ— ä¸­æœŸèåˆ:")
    for k, v in metrics_without.items():
        print(f"  {k}: {v:.4f}")

    print(f"\næœ‰ä¸­æœŸèåˆ:")
    for k, v in metrics_with.items():
        print(f"  {k}: {v:.4f}")

    # è®¡ç®—ç±»åˆ†ç¦»åº¦
    print("\n" + "=" * 80)
    print("8ï¸âƒ£ è®¡ç®—ç±»åˆ†ç¦»åº¦")
    print("=" * 80)

    sep_without = compute_class_separation(features_without, filtered_systems, class_pair[0], class_pair[1])
    sep_with = compute_class_separation(features_with, filtered_systems, class_pair[0], class_pair[1])

    print(f"\næ— ä¸­æœŸèåˆ:")
    print(f"  ç±»é—´è·ç¦»: {sep_without['inter_class_dist']:.4f}")
    print(f"  ç±»å†…è·ç¦»1 ({class_pair[0]}): {sep_without['intra_class_dist_1']:.4f}")
    print(f"  ç±»å†…è·ç¦»2 ({class_pair[1]}): {sep_without['intra_class_dist_2']:.4f}")
    print(f"  åˆ†ç¦»æ¯”ç‡: {sep_without['separation_ratio']:.4f}")

    print(f"\næœ‰ä¸­æœŸèåˆ:")
    print(f"  ç±»é—´è·ç¦»: {sep_with['inter_class_dist']:.4f}")
    print(f"  ç±»å†…è·ç¦»1 ({class_pair[0]}): {sep_with['intra_class_dist_1']:.4f}")
    print(f"  ç±»å†…è·ç¦»2 ({class_pair[1]}): {sep_with['intra_class_dist_2']:.4f}")
    print(f"  åˆ†ç¦»æ¯”ç‡: {sep_with['separation_ratio']:.4f}")

    # é™ç»´
    print("\n" + "=" * 80)
    print("9ï¸âƒ£ é™ç»´å¯è§†åŒ–")
    print("=" * 80)

    embedded_without = apply_reduction(features_without, method=args.reduction_method, n_components=2)
    embedded_with = apply_reduction(features_with, method=args.reduction_method, n_components=2)

    # å¯è§†åŒ–
    print("\n" + "=" * 80)
    print("ğŸ”Ÿ ç”Ÿæˆå¯è§†åŒ–å›¾åƒ")
    print("=" * 80)

    comparison_path = output_dir / f"hard_class_{class_pair[0]}_vs_{class_pair[1]}.png"
    plot_hard_class_comparison(embedded_without, embedded_with, filtered_systems,
                               metrics_without, metrics_with,
                               sep_without, sep_with,
                               class_pair, comparison_path)

    separation_path = output_dir / f"separation_metrics_{class_pair[0]}_vs_{class_pair[1]}.png"
    plot_separation_metrics(sep_without, sep_with, class_pair, separation_path)

    # ä¿å­˜ç»“æœæ‘˜è¦
    summary_path = output_dir / f"summary_{class_pair[0]}_vs_{class_pair[1]}.txt"
    with open(summary_path, 'w') as f:
        f.write("=" * 80 + "\n")
        f.write("éš¾åˆ†æ ·æœ¬å¯è§†åŒ–åˆ†æç»“æœ (Hard Class Subset)\n")
        f.write("=" * 80 + "\n\n")
        f.write(f"æ•°æ®é›†: {args.dataset} - {args.property}\n")
        f.write(f"æ™¶ç³»å¯¹: {CRYSTAL_SYSTEMS.get(class_pair[0], class_pair[0])} vs "
                f"{CRYSTAL_SYSTEMS.get(class_pair[1], class_pair[1])}\n")
        f.write(f"æ ·æœ¬æ•°: {len(filtered_systems)}\n")
        f.write(f"  {CRYSTAL_SYSTEMS.get(class_pair[0], class_pair[0])}: "
                f"{filtered_systems.count(class_pair[0])}\n")
        f.write(f"  {CRYSTAL_SYSTEMS.get(class_pair[1], class_pair[1])}: "
                f"{filtered_systems.count(class_pair[1])}\n")
        f.write(f"é™ç»´æ–¹æ³•: {args.reduction_method.upper()}\n\n")

        f.write("=" * 80 + "\n")
        f.write("èšç±»æŒ‡æ ‡å¯¹æ¯”\n")
        f.write("=" * 80 + "\n\n")
        f.write(f"{'æŒ‡æ ‡':<30} {'æ— èåˆ':<15} {'æœ‰èåˆ':<15} {'æ”¹è¿›':<15}\n")
        f.write("-" * 80 + "\n")

        for key in ['silhouette', 'davies_bouldin', 'calinski_harabasz']:
            val_without = metrics_without[key]
            val_with = metrics_with[key]

            if not np.isnan(val_without) and not np.isnan(val_with):
                if key == 'davies_bouldin':
                    improvement = (val_without - val_with) / val_without * 100
                    arrow = "â†“" if val_with < val_without else "â†‘"
                else:
                    improvement = (val_with - val_without) / abs(val_without) * 100
                    arrow = "â†‘" if val_with > val_without else "â†“"

                f.write(f"{key:<30} {val_without:<15.4f} {val_with:<15.4f} "
                       f"{arrow}{abs(improvement):<13.1f}%\n")

        f.write("\n" + "=" * 80 + "\n")
        f.write("ç±»åˆ†ç¦»åº¦æŒ‡æ ‡\n")
        f.write("=" * 80 + "\n\n")
        f.write(f"{'æŒ‡æ ‡':<40} {'æ— èåˆ':<15} {'æœ‰èåˆ':<15} {'æ”¹è¿›':<15}\n")
        f.write("-" * 80 + "\n")

        # ç±»é—´è·ç¦»
        val_without = sep_without['inter_class_dist']
        val_with = sep_with['inter_class_dist']
        improvement = (val_with - val_without) / val_without * 100
        arrow = "â†‘" if val_with > val_without else "â†“"
        f.write(f"{'Inter-class Distance (ç±»é—´è·ç¦»)':<40} {val_without:<15.4f} "
               f"{val_with:<15.4f} {arrow}{abs(improvement):<13.1f}%\n")

        # å¹³å‡ç±»å†…è·ç¦»
        val_without = (sep_without['intra_class_dist_1'] + sep_without['intra_class_dist_2']) / 2
        val_with = (sep_with['intra_class_dist_1'] + sep_with['intra_class_dist_2']) / 2
        improvement = (val_without - val_with) / val_without * 100  # ç±»å†…è·ç¦»è¶Šå°è¶Šå¥½
        arrow = "â†“" if val_with < val_without else "â†‘"
        f.write(f"{'Avg Intra-class Distance (å¹³å‡ç±»å†…è·ç¦»)':<40} {val_without:<15.4f} "
               f"{val_with:<15.4f} {arrow}{abs(improvement):<13.1f}%\n")

        # åˆ†ç¦»æ¯”ç‡
        val_without = sep_without['separation_ratio']
        val_with = sep_with['separation_ratio']
        improvement = (val_with - val_without) / val_without * 100
        arrow = "â†‘" if val_with > val_without else "â†“"
        f.write(f"{'Separation Ratio (åˆ†ç¦»æ¯”ç‡)':<40} {val_without:<15.4f} "
               f"{val_with:<15.4f} {arrow}{abs(improvement):<13.1f}%\n")

    print(f"âœ“ ç»“æœæ‘˜è¦å·²ä¿å­˜: {summary_path}")

    print("\n" + "=" * 80)
    print("âœ… åˆ†æå®Œæˆï¼")
    print("=" * 80)
    print(f"\nç»“æœä¿å­˜åœ¨: {output_dir}")
    print(f"  - hard_class_{class_pair[0]}_vs_{class_pair[1]}.png : éš¾åˆ†æ ·æœ¬å¯¹æ¯”å›¾")
    print(f"  - separation_metrics_{class_pair[0]}_vs_{class_pair[1]}.png : åˆ†ç¦»åº¦æŒ‡æ ‡å›¾")
    print(f"  - summary_{class_pair[0]}_vs_{class_pair[1]}.txt : ç»“æœæ‘˜è¦")


if __name__ == '__main__':
    main()
